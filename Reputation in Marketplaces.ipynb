{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reputation_api\n",
    "\n",
    "# Reputation Service API, including Rating Service and Ranking Service\n",
    "\n",
    "import abc\n",
    "\n",
    "#TODO @anton provide proper parameters for the methods\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reputation Generic Service interface definition\n",
    "\"\"\"        \n",
    "class ReputationService(abc.ABC):\n",
    "\n",
    "\t\"\"\"\n",
    "\tInput: dict of all parameters that needs to be set (not listed parameters are not affected)\n",
    "\tOutput: 0 on success, integer error code on error \n",
    "\t\"\"\"\n",
    "\t@abc.abstractmethod\n",
    "\tdef set_parameters(self,parameters):\n",
    "\t\tpass\n",
    "\n",
    "\t@abc.abstractmethod\n",
    "\tdef get_parameters(self):\n",
    "\t\tpass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Reputation Rating Service interface definition\n",
    "\"\"\"        \n",
    "class RatingService(ReputationService):\n",
    "\n",
    "\t\"\"\"\n",
    "\tInput: List of dicts with the key-value pairs for the attributes: \"from\",\"type\",\"to\",\"value\",\"weight\",\"time\"\n",
    "\tOutput: 0 on success, integer error code on error \n",
    "\t\"\"\"\n",
    "\t@abc.abstractmethod\n",
    "\tdef put_ratings(self,ratings):\n",
    "\t\tpass\n",
    "\n",
    "\t\"\"\"\n",
    "\tInput: filter as dict of the following:\n",
    "\t\tsince - starting time inclusively\n",
    "\t\tuntil - ending time inclusively\n",
    "\t\tids - list of ids to retrieve incoming AND outgoing ratings BOTH\n",
    "\t\tfrom - list of ids to retrieve outgoing ratings ONLY (TODO later)\n",
    "\t\tto - list of ids to retrieve incoming ratings ONLY (TODO later)\n",
    "\tOutput: tuple of the pair:\n",
    "\t\t0 on success, integer error code on error\n",
    "\t\tList of dicts with the key-value pairs for the attributes: \"from\",\"type\",\"to\",\"value\",\"weight\",\"time\"\n",
    "\t\"\"\"\n",
    "\t@abc.abstractmethod\n",
    "\tdef get_ratings(self,filter):\n",
    "\t\tpass\n",
    "\n",
    "\t\"\"\"\n",
    "\tInput: None\n",
    "\tOutput: 0 on success, integer error code on error \n",
    "\t\"\"\"\n",
    "\t@abc.abstractmethod\n",
    "\tdef clear_ratings(self):\n",
    "\t\tpass\n",
    "\t\t\n",
    "\"\"\"\n",
    "Reputation Ranking Service interface definition\n",
    "\"\"\"        \n",
    "class RankingService(ReputationService):\n",
    "\n",
    "\t\"\"\"\n",
    "\tInput: Date to update the ranks for\n",
    "\tOutput: 0 on success, integer error code on error \n",
    "\t\"\"\"\n",
    "\t@abc.abstractmethod\n",
    "\tdef update_ranks(self,date):\n",
    "\t\tpass\n",
    "\n",
    "\t\"\"\"\n",
    "\tInput: Date and list of dicts with two key-value pairs for \"id\" and \"rank\" \n",
    "\tOutput: 0 on success, integer error code on error \n",
    "\t\"\"\"\n",
    "\t@abc.abstractmethod\n",
    "\tdef put_ranks(self,date,ranks):\n",
    "\t\tpass\n",
    "\n",
    "\t\"\"\"\n",
    "\tInput: filter as dict of the following:\n",
    "\t\tdate - date to provide the ranks\n",
    "\t\tids - list of ids to retrieve the ranks\n",
    "\tOutput: tuple of the pair:\n",
    "\t\t0 on success, integer error code on error\n",
    "\t\tList of dicts with the two key-value pairs for \"id\" and \"rank\"\n",
    "\t\"\"\"\n",
    "\t@abc.abstractmethod\n",
    "\tdef get_ranks(self,filter):\n",
    "\t\tpass\n",
    "\n",
    "\t\"\"\"\n",
    "\tInput: None\n",
    "\tOutput: 0 on success, integer error code on error \n",
    "\t\"\"\"\n",
    "\t@abc.abstractmethod\n",
    "\tdef clear_ranks(self):\n",
    "\t\tpass\n",
    "\n",
    "\t@abc.abstractmethod\n",
    "\tdef get_ranks_dict(self,filter):\n",
    "\t\tpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reputation service base\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Abstract Reputation Service wrapper around\n",
    "\"\"\"        \n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "\n",
    "class ReputationServiceBase(RatingService,RankingService):\n",
    "\n",
    "\tdef __init__(self, name, verbose=False):\n",
    "\t\tself.name = name #service parameter, no impact on algorithm, name of the storage scheme\n",
    "\t\tself.verbose = verbose #service parameter, no impact on algorithm, impact on log level \n",
    "\t\tself.parameters = {}\n",
    "\t\tself.parameters['default'] = 0.5 # default (initial) reputation rank\n",
    "\t\tself.parameters['decayed'] = 0.0 # decaying (final) reputaion rank, may be equal to default one\n",
    "\t\tself.parameters['conservatism'] = 0.5 # blending factor between previous (default) rank and differential one \n",
    "\t\tself.parameters['precision'] = 0.01 # Used to dound/up or round down financaial values or weights as value = round(value/precision)\n",
    "\t\tself.parameters['weighting'] = True # forces to weight ratings with financial values, if present\n",
    "\t\tself.parameters['denomination'] = False # forces to denominate weighted ratings with sum of weights\n",
    "\t\tself.parameters['fullnorm'] = True # full-scale normalization of incremental ratings\n",
    "\t\tself.parameters['liquid'] = True # forces to account for rank of rater\n",
    "\t\tself.parameters['logranks'] = True # applies log10 to ranks\n",
    "\t\tself.parameters['logratings'] = True # applies log10(1+value) to financial values and weights\n",
    "\t\tself.parameters['downrating'] = False # boolean option with True value to translate original explicit rating values in range 0.5-0.0 to negative values in range 0.0 to -1.0 and original values in range 1.0-0.5 to interval 1.0-0.0, respectively\n",
    "\t\tself.parameters['update_period'] = 1 # number of days to update reputation state, considered as observation period for computing incremental reputations\n",
    "\t\tself.parameters['aggregation'] = False #TODO support in Aigents, aggregated with weighted average of ratings across the same period\n",
    "\t\tself.parameters['unrated'] = False # whether to store default ranks of unrated agents and let them decay \n",
    "\t\tself.parameters['ratings'] = 1.0 # to which extent account contribution of explicit and implicit ratings to reputation\n",
    "\t\tself.parameters['spendings'] = 0.0 # to which extent account contribution of spendings (\"prrof-of-burn\") to reputation\n",
    "\t\tself.parameters['parents'] = 0.0 # to which extent reputation of the \"child\" (product) is affected by the reputation of the \"parent\" (vendor)\n",
    "\t\tself.parameters['predictiveness'] = 0.0 # to which extent account rank is based on consensus between social consensus and ratings provided by the account\n",
    "\t\tself.parameters['rating_bias'] = False # whether to weigth ratings based on pessimism of the prior ratings\n",
    "\t\t\n",
    "\n",
    "\t\"\"\"\n",
    "\tUtility wrapper around get_ranks, returns None in case of error, so ranks  = get_ranks_dict(...) should be checked for None, and if it is None, the get_ranks(...) may be used to decipher the error code.\n",
    "\tInput: filter as dict of the following:\n",
    "\t\tdate - date to provide the ranks\n",
    "\t\tids - list of ids to retrieve the ranks\n",
    "\tOutput:\n",
    "\t\tdictionary of key-value pairs with reputation \"ranks\" by \"id\" on success, None on error\n",
    "\t\"\"\"\n",
    "\tdef get_ranks_dict(self,filter):\n",
    "\t\tranks_dict = {}\n",
    "\t\tres, ranks = self.get_ranks(filter)\n",
    "\t\tif res != 0:\n",
    "\t\t\treturn None\n",
    "\t\tfor rank in ranks:\n",
    "\t\t\tranks_dict[rank['id']] = rank['rank']\n",
    "\t\treturn ranks_dict\n",
    "\t\n",
    "\t\"\"\"\n",
    "\tTODO: implement in derived imlementations\n",
    "\t\"\"\"\n",
    "\tdef set_parent(self,parent_id,list_of_children_ids):\n",
    "\t\treturn 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reputation_calculation\n",
    "\n",
    "### Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from logging import debug\n",
    "from math import ceil, floor\n",
    "\n",
    "### Get strings between two strings; will be useful when extracting the date.\n",
    "def find_between( s, first, last ):\n",
    "    try:\n",
    "        start = s.index( first ) + len( first )\n",
    "        end = s.index( last, start )\n",
    "        return s[start:end]\n",
    "    except ValueError:\n",
    "        return \"\"\n",
    "### Get strings between two strings; will be useful when extracting the date. Different way of implementing the\n",
    "### same thing as above.\n",
    "# def find_between_r( s, first, last ):\n",
    "#     try:\n",
    "#         start = s.rindex( first ) + len( first )\n",
    "#         end = s.rindex( last, start )\n",
    "#         return s[start:end]\n",
    "#     except ValueError:\n",
    "#         return \"\"\n",
    "\n",
    "### Below two functions will make sure we get difference between times.\n",
    "def parse_prefix(line, fmt):\n",
    "    cover = len(datetime.datetime.now().strftime(fmt))\n",
    "    return datetime.strptime(line[:cover], fmt)\n",
    "### Calculate days between d2 and d1.\n",
    "def days_between(d1, d2):\n",
    "    return abs((d2 - d1).days) \n",
    "\n",
    "def downratings(condition,ratings):\n",
    "    if condition:\n",
    "    \t### it is expected current_max to be 1.\n",
    "        current_max = 1### Note that maximum is set to 1 as per documentation. We do not allow \n",
    "        ### values higher than 1.\n",
    "        i = 0\n",
    "        while i<len(ratings):\n",
    "            if ratings[i]['value']>current_max:\n",
    "                ### as soon as we find 1 value above 1, we raise an error.\n",
    "                raise ValueError(\"Downratings are not on the scale of 0 to 1, as required.\")\n",
    "            i+=1\n",
    "        \n",
    "        i=0\n",
    "        while i<len(ratings):\n",
    "        \t### it is expected ratings to be converted to range -100 to +100 (or -1.0 to +1.0 on -100% to +100% scale)\n",
    "            ratings[i]['value'] = ratings[i]['value']/current_max\n",
    "            ### current_max is set to 1, so we are essentially dividing by 1. Now, below, we are converting everything\n",
    "            ### to the range of -1 to 1.\n",
    "            if ratings[i]['value']<0.25:\n",
    "                ratings[i]['value'] = ratings[i]['value']/0.25-1\n",
    "            else:\n",
    "                ratings[i]['value'] = (ratings[i]['value']-0.25)/0.75\n",
    "            ### Then we multiply by 100, so we get it btw -100 and 100.    \n",
    "            ratings[i]['value'] = ratings[i]['value'] * 100\n",
    "            i+=1\n",
    "        return(ratings)\n",
    "    else:\n",
    "        ### If downratings=false, then we do nothing.\n",
    "        return(ratings)\n",
    "### Rounding is fixed here. Normal rounding in Python rounds 0.5 to 0, this little function prevents that.    \n",
    "def my_round(n, ndigits):\n",
    "    part = n * 10 ** ndigits\n",
    "    delta = part - int(part)\n",
    "    # always round \"away from 0\"\n",
    "    if delta >= 0.5 or -0.5 < delta <= 0:\n",
    "        part = ceil(part)\n",
    "    else:\n",
    "        part = floor(part)\n",
    "    return part / (10 ** ndigits)\n",
    "\n",
    "### Transforming ratings to logarithm, if needed. logratings might or might not be set to true.\n",
    "def transform_ratings(ratings, logratings):\n",
    "    if logratings:\n",
    "        i=0        \n",
    "        while i<len(ratings):\n",
    "            ### Transformations of weight depending on the value. If smaller than 0, then we need to adjust a bit.\n",
    "            if ratings[i]['weight']!=None:\n",
    "                if ratings[i]['weight']<0:\n",
    "                    ratings[i]['weight'] = -np.log10(1-ratings[i]['weight'])\n",
    "                else:\n",
    "                    ratings[i]['weight'] = np.log10(1+ratings[i]['weight'])\n",
    "            else:\n",
    "                ### We do the same with value.\n",
    "                if ratings[i]['value']<0:\n",
    "                    ratings[i]['value'] = -np.log10(1-ratings[i]['value'])\n",
    "                else:\n",
    "                    ratings[i]['value'] = np.log10(1+ratings[i]['value'])#np.log10(1+ratings[i]['value'])\n",
    "            i+=1\n",
    "    return(ratings)\n",
    "### Weight calculation. Only problem is if we have no value number. If we do, we just call logratings_precision.\n",
    "def weight_calc(value,lograting,precision,weighting):\n",
    "    if value != None:\n",
    "        return(logratings_precision(value,lograting,precision,weighting))\n",
    "    else:\n",
    "        return(1,None)\n",
    "###   Get starting dates and first occurances of each addresses. Also, preparation or arrays and other data\n",
    "### to be used in the future.\n",
    "### Note; Given that we take an approach where we don't need first_occurance, we decide to put as a default option\n",
    "### need_occurance=False.\n",
    "def reputation_calc_p1(new_subset,conservatism,precision,temporal_aggregation=False,need_occurance=False,\n",
    "                       logratings=False,downrating=False,weighting=True,rater_bias = None,averages = None):\n",
    "    ### need_occurance is set to false by default and might even be removed for good. It was made in order to\n",
    "    ### facilitate some other approaches towards updating rankings, which we decided not to use in the end.\n",
    "    #### We will need from, to, amount, the rest is not necessary to have - let's save memory.\n",
    "    ### Now we will just store the first occurance of each account in a dictionary.\n",
    "    ##  Inputs are dictionaries, arrays and True/False statements.\n",
    "    ### We change the subeset that is incoming in order to put downratings transformation.\n",
    "    new_subset = downratings(downrating,new_subset)\n",
    "    if rater_bias != None:\n",
    "        rater_bias,average_rating = update_biases(rater_bias,new_subset,conservatism)\n",
    "        \n",
    "        our_averages = dict()\n",
    "        for k in averages:\n",
    "            for j in averages[k].keys():\n",
    "                if j in our_averages.keys():\n",
    "                    our_averages[j].append(averages[k][j])\n",
    "                else:\n",
    "                    our_averages[j] = [averages[k][j]]\n",
    "        our_average = dict()\n",
    "        for k in our_averages.keys():\n",
    "            our_average[k] = np.mean(our_averages[k])\n",
    "        new_subset = fix_rater_bias(new_subset,rater_bias,our_average)    \n",
    "            \n",
    "    i=0\n",
    "    new_array = []\n",
    "    israting = True\n",
    "    while i<len(new_subset):\n",
    "        if 'value' in list(new_subset[i].keys()):\n",
    "            ### put ratings in array. Note, that we don't always have information about rating, that is\n",
    "            ### what ratings were given by specific customers.\n",
    "            ### This array is standardized.\n",
    "            if 'weight' in new_subset[i].keys():\n",
    "                new_array.append([new_subset[i]['from'],new_subset[i]['to'],new_subset[i]['weight'],new_subset[i]['value']])\n",
    "            else:\n",
    "                new_array.append([new_subset[i]['from'],new_subset[i]['to'],None,new_subset[i]['value']])\n",
    "        else:\n",
    "            israting = False\n",
    "            if 'weight' in new_subset[i].keys():\n",
    "                new_array.append([new_subset[i]['from'],new_subset[i]['to'],new_subset[i]['weight']])\n",
    "            else:\n",
    "                new_array.append([new_subset[i]['from'],new_subset[i]['to'],None])\n",
    "        i+=1\n",
    "    ### We make array of dates and transactions to specific agents.\n",
    "    dates_array = []\n",
    "    to_array = []\n",
    "    i = 0\n",
    "    ### we have array of only dates and array of ids which are getting transactions.\n",
    "    while i<len(new_subset):\n",
    "        dates_array.append(new_subset[i]['time'])\n",
    "        to_array.append(new_subset[i]['to'])\n",
    "        i+=1\n",
    "    ### In case we have temporal aggregation\n",
    "    if temporal_aggregation:\n",
    "        from_data = []\n",
    "        to_data = to_array\n",
    "        i = 0\n",
    "        while i<len(new_array):\n",
    "            ### we merge all the 'from' data.\n",
    "            from_data.append(int(new_array[i][0]))\n",
    "            i+=1\n",
    "            \n",
    "        ### Temporal aggregation=True;\n",
    "        ### First let's just find all the duplicates;\n",
    "        ### We merge from and to arrays and look for unique ones...\n",
    "        ### The idea of this code is that if there were multiple transactions in a day, we merge them and look at\n",
    "        ### the averages.\n",
    "        merged = []\n",
    "        i=0\n",
    "        while i<len(from_data):\n",
    "            ### We get all the from-to id combinations.\n",
    "            newnr = str(from_data[i])+\"_\"+str(to_data[i])\n",
    "            merged.append(newnr)\n",
    "            i+=1\n",
    "        ### Here we just count how many times it appears\n",
    "        already_used = {}\n",
    "        ### We count how many times each combination appeared.\n",
    "        for i in merged:\n",
    "            if i in already_used.keys():\n",
    "                already_used[i] = already_used[i] + 1\n",
    "            else:\n",
    "                already_used[i] = 1\n",
    "        ### Good, now we know exact nr of transactions for each pair...    \n",
    "        \n",
    "        #### merged data has the same indexing as new_array. \n",
    "        i = 0\n",
    "        ### If exists, pass, otherwise this:\n",
    "        ### We sum up each feature.\n",
    "        already_used2 = {}\n",
    "        new_array2 = []\n",
    "        to_array2 = []\n",
    "        amounts = {}\n",
    "        ratings = {}\n",
    "        while i<len(merged):\n",
    "            if merged[i] in already_used2.keys():\n",
    "                new_rating, new_weight = weight_calc(new_array[i],logratings,precision,weighting)\n",
    "                amounts[merged[i]] = amounts[merged[i]] + new_rating\n",
    "                if israting:\n",
    "                    ### then we sum up ratings.\n",
    "                    ratings[merged[i]] = ratings[merged[i]] + new_array[i][3]               \n",
    "            else:\n",
    "                already_used2[merged[i]]=1\n",
    "                new_rating, new_weight = weight_calc(new_array[i],logratings,precision,weighting)\n",
    "                amounts[merged[i]] = new_rating\n",
    "                if israting:\n",
    "                    ratings[merged[i]] = new_array[i][3]                        \n",
    "            i+=1\n",
    "        i=0\n",
    "        ### And divide it by the number of times it appears - getting average.\n",
    "        already_used2 = {}\n",
    "        while i<len(merged):\n",
    "            if merged[i] in already_used2.keys():\n",
    "                pass\n",
    "            else:\n",
    "                already_used2[merged[i]]=1\n",
    "                ### Just set some value.\n",
    "                new_array2.append(new_array[i])\n",
    "                new_array2[len(new_array2)-1][2] = amounts[merged[i]]/already_used[merged[i]]\n",
    "                if israting:\n",
    "                    new_array2[len(new_array2)-1][3] = ratings[merged[i]]/already_used[merged[i]]\n",
    "                \n",
    "                to_array2.append(to_array[i])\n",
    "            i+=1\n",
    "        new_array = new_array2\n",
    "        to_array = to_array2\n",
    "    if rater_bias != None:\n",
    "        return(new_array,dates_array,to_array,rater_bias,average_rating)\n",
    "    else:\n",
    "        return(new_array,dates_array,to_array,rater_bias)\n",
    "### Get new reputations in case we do not yet have the old ones.\n",
    "def update_reputation(reputation,new_array,default_reputation,spendings):\n",
    "    i = 0\n",
    "    new_ids = []\n",
    "    while i<len(new_array):\n",
    "        ### If we already have it, we do nothing in this function...\n",
    "        ### The rest is also checking for \"to\" transactions and doing the same thing there..\n",
    "        if new_array[i][1] in reputation:\n",
    "            ### If reputation already has an id, we go on, otherwise we add default reputation.\n",
    "            pass\n",
    "        else:\n",
    "            new_ids.append(new_array[i][1])\n",
    "            reputation[new_array[i][1]] = default_reputation\n",
    "        ### If we have spendings, we need reputation also for buyers. We make it default if it does not exist yet.    \n",
    "        if spendings>0:\n",
    "            if new_array[i][0] in reputation:\n",
    "                pass\n",
    "            else:\n",
    "                new_ids.append(new_array[i][0])\n",
    "                reputation[new_array[i][0]] = default_reputation\n",
    "            \n",
    "        i+=1      \n",
    "    return(reputation)\n",
    "\n",
    "\n",
    "### Logratings calculation, calculating weights and fixing for precision.\n",
    "def logratings_precision(rating,lograting,precision,weighting):\n",
    "    new_weight = None # assume no weight computed by default\n",
    "    ### if weighting = False, then we return values only.\n",
    "    if not weighting:\n",
    "        return(rating[3],None)\n",
    "    if lograting:\n",
    "        ### We go through few posibilities about what can happen.\n",
    "        ### If there are no weights then:\n",
    "        if rating[2] == None:\n",
    "            ### depending on precision, we make a log transformation with or without it.\n",
    "            if precision==None:\n",
    "                new_rating = np.log10(1+ rating[3])\n",
    "            else:\n",
    "                new_rating = np.log10(1+ int(rating[3]/precision))\n",
    "        else:\n",
    "            ### if we have no values;\n",
    "            if rating[3] == None:\n",
    "                ### Then we work with weights only.\n",
    "                if precision==None:\n",
    "                    new_rating = np.log10(1+ rating[2])\n",
    "                else:\n",
    "                    new_rating = np.log10(1+ int(rating[2]/precision))\n",
    "            else:\n",
    "                ### if we have values and weights, we multiply them together.\n",
    "                if precision==None:\n",
    "                    new_weight = np.log10(1+ rating[2])\n",
    "                else:\n",
    "                    new_weight = np.log10(1+ rating[2]/precision)\n",
    "                new_rating = my_round(new_weight * rating[3],0)\n",
    "    else:\n",
    "        ### If not lograting, we do not do log transformation.\n",
    "        if precision==None:\n",
    "            precision=1\n",
    "        if rating[2] == None:\n",
    "            new_rating = rating[3]/precision\n",
    "        else:\n",
    "            if rating[3] == None:\n",
    "                new_rating = rating[2]/precision\n",
    "            else:\n",
    "                new_weight = rating[2]/precision\n",
    "                new_rating = rating[3] * new_weight\n",
    "    new_rating = my_round(new_rating,0) \n",
    "    return(new_rating,new_weight) #return weighted value Fij*Qij to sum and weight Qij to denominate later in dRit = Î£j (Fij * Qij * Rjt-1 ) / Î£j (Qij)\n",
    "\n",
    "def update_biases(previous_bias,new_arrays, conservatism):\n",
    "    all_rating = dict()\n",
    "    i = 0\n",
    "    while i<len(new_arrays):\n",
    "        if new_arrays[i]['from'] in all_rating.keys():\n",
    "            all_rating[new_arrays[i]['from']].append(new_arrays[i]['value'])\n",
    "        else:\n",
    "            all_rating[new_arrays[i]['from']] = [new_arrays[i]['value']]\n",
    "        i+=1\n",
    "    averages = dict()\n",
    "    for k in all_rating.keys():\n",
    "        averages[k] = np.mean(all_rating[k])\n",
    "    unique_ids = []\n",
    "    for k in averages.keys():\n",
    "        if k in unique_ids:\n",
    "            pass\n",
    "        else:\n",
    "            unique_ids.append(k)\n",
    "    for k in previous_bias.keys():\n",
    "        if k in unique_ids:\n",
    "            pass\n",
    "        else:\n",
    "            unique_ids.append(k)\n",
    "    for k in averages.keys():\n",
    "        if k in unique_ids:\n",
    "            pass\n",
    "        else:\n",
    "            unique_ids.append(k)\n",
    "        \n",
    "        \n",
    "    new_bias = dict()\n",
    "    for k in unique_ids:\n",
    "        if k in averages.keys() and k in previous_bias.keys():\n",
    "            new_bias[k] = averages[k] * (1-conservatism) + conservatism * previous_bias[k]\n",
    "        else:\n",
    "            if k in averages.keys():\n",
    "                new_bias[k] = averages[k] * (1-conservatism) + conservatism ### This is how we are supposed to \n",
    "                ### treat first customer based on the https://docs.google.com/document/d/1-O7avb_zJKvCXRvD0FmvyoVZdSmkDMlXRB5wsavpSAM/edit#\n",
    "            if k in previous_bias.keys():\n",
    "                new_bias[k] = previous_bias[k]\n",
    "                \n",
    "    return(new_bias,averages)\n",
    "\n",
    "\n",
    "def fix_rater_bias(new_array,biases,average):\n",
    "    i = 0\n",
    "    while i<len(new_array):\n",
    "        if new_array[i]['from'] in average.keys():\n",
    "            new_array[i]['value'] = new_array[i]['value'] * (1-my_round(average[new_array[i]['from']],0))\n",
    "        else:\n",
    "            new_array[i]['value'] = new_array[i]['value']\n",
    "        \n",
    "        i+=1\n",
    "    return (new_array)\n",
    "\n",
    "### Get updated reputations, new calculations of them...\n",
    "### We calculate differential here.\n",
    "def calculate_new_reputation(logging,new_array,to_array,reputation,rating,precision,previous_rep,default,unrated,normalizedRanks=True,weighting=True,denomination=True,liquid = False,logratings=False,logranks=True,predictiveness = 0,predictive_data = dict()):\n",
    "    ### The output will be mys; this is the rating for that specific day (or time period).\n",
    "    ### This is needed; first create records for each id. mys is a differential.\n",
    "    mys = {}\n",
    "    myd = {} # denominators \n",
    "    i = 0\n",
    "    while i<len(new_array):\n",
    "        if new_array[i][1] in mys:\n",
    "            pass\n",
    "        else:\n",
    "            ### We first set all differential ids to 0.\n",
    "            mys[new_array[i][1]] = 0\n",
    "        i+=1\n",
    "    ## getting the formula for mys.\n",
    "    unique_ids = np.unique(to_array)\n",
    "    k=0\n",
    "    i = 0\n",
    "    to_array = np.array(to_array)\n",
    "    ### Formula differs based on conditions. If ratings are included, formula includes ratings, then there are weights, etc.\n",
    "    prev_rep1 = dict()\n",
    "    prev_rep1a = dict()\n",
    "    while i<len(unique_ids):\n",
    "        amounts = []\n",
    "        denominators = []\n",
    "        ### Here we get log transformation of each amount value. \n",
    "        get_subset = np.where(to_array==unique_ids[i])[0]\n",
    "        for k in get_subset:\n",
    "            if weighting:\n",
    "                ### Calculate ratings and weights.\n",
    "                new_rating, new_weight = weight_calc(new_array[k],logratings,precision,weighting)\n",
    "                ### Then we multiply this with rater's current reputation. Few options are taken into account, such as\n",
    "                ### if it is liquid reputation, then we set it to 1...\n",
    "                my_rater_rep, prev_rep1 = rater_reputation(reputation,new_array[k][0],default,previous_rep,liquid,new_array[k][1],predictiveness,predictive_data)\n",
    "                for k in prev_rep1.keys():\n",
    "                    prev_rep1a[k] = prev_rep1[k]\n",
    "                amounts.append(new_rating * my_rater_rep)\n",
    "                text = \"from: \" + str(new_array[i][0]) + \", to: \" + str(new_array[i][1]) + \", value: \" + str(new_array[i][2]) + \", weight: \" + str(new_array[i][3]),\" calculated rating: \",new_rating\n",
    "                logging.debug(text)\n",
    "                ### if we have weights and denomination, then we append some denominators.\n",
    "                if denomination and new_weight is not None:\n",
    "                \tdenominators.append(new_weight) # denomination by sum of weights in such case\n",
    "            else:\n",
    "                new_rating, new_weight = weight_calc(new_array[k],logratings,precision,weighting)\n",
    "                new_rating = my_round(new_rating,0)\n",
    "                my_rater_rep, prev_rep1 = rater_reputation(reputation,new_array[k][0],default,previous_rep,liquid,new_array[k][1],predictiveness,predictive_data)\n",
    "                for k in prev_rep1.keys():\n",
    "                    prev_rep1a[k] = prev_rep1[k]\n",
    "                amounts.append(new_rating * my_rater_rep)\n",
    "                text = \"from: \" + new_array[i][0] + \", to: \" + str(new_array[i][1]) + \", value: \" + str(new_array[i][2]) + \", weight: \" + str(new_array[i][3]),\" calculated rating: \",str(new_rating)\n",
    "                logging.debug(text)\n",
    "                #no need for denomination by sum of weights in such case \n",
    "        ### After we are done collecting sums for certain ids, we sum up everything we have.\n",
    "        mys[unique_ids[i]] = sum(amounts)\n",
    "        ### If we have denominators, we also sum them up.\n",
    "        if weighting:\n",
    "            if len(denominators) > 0:\n",
    "                myd[unique_ids[i]] = sum(denominators)\n",
    "#\n",
    "        i+=1\n",
    "    ### Let's update the records from previous reputations and how we update them (for raters)\n",
    "    for k in prev_rep1a.keys():\n",
    "        previous_rep[k] = prev_rep1a[k]\n",
    "    ### If we have weighting and denomination, then we \n",
    "    if weighting:\n",
    "        if denomination and len(mys) == len(myd):\n",
    "            for k, v in mys.items():\n",
    "                ### divide mys values with denomination values.\n",
    "                mys[k] = v / myd[k]\n",
    "    ### nr 5.\n",
    "    ### Here we make trasformation in the same way as described in point 5 in documentation doc.\n",
    "    text = \"Differential before log transformation: \" + str(mys)\n",
    "    logging.debug(text)\n",
    "    if logranks:\n",
    "        for k in mys.keys():\n",
    "            if mys[k]<0:\n",
    "                mys[k] = -np.log10(1 - mys[k])\n",
    "            else:\n",
    "                mys[k] = np.log10(1 + mys[k])\n",
    "    logging.debug(text)\n",
    "    return(mys,previous_rep)\n",
    "\n",
    "### normalizing differential.\n",
    "def normalized_differential(mys,normalizedRanks,our_default,spendings,log=True):\n",
    "    ### Nr 6;\n",
    "    ### We divide it by max value, as specified. There are different normalizations possible...\n",
    "    ### lograting transformation as made by Anton. Since this was done few lines above, I believe this is redundant coding.\n",
    "    if log:\n",
    "        for k in mys.keys():\n",
    "            mys[k] = -np.log10(1 - mys[k]) if mys[k] < 0 else np.log10(1 + mys[k])\n",
    "    ### It could as well be deleted; in this case test_spendings_normalization wll have different result.        \n",
    "            \n",
    "    ### Then we use maximums, either from what we have or set it to one by default.\n",
    "    max_value = max(mys.values(), default=1)\n",
    "    min_value = min(mys.values(), default=0)\n",
    "    if max_value==0: #normalized zeroes are just zeroes\n",
    "    \treturn(mys)\n",
    "    ### Now some rare cases, such as we have only one value of differential and what to do then.\n",
    "    if max_value==min_value:\n",
    "        min_value = max_value - our_default ### as the solution to issue #157\n",
    "        if min_value==max_value and spendings>0:\n",
    "            min_value = max_value - 1\n",
    "        \n",
    "    ### Now, way of solving this problem in a bit more common way:        \n",
    "    for k in mys.keys():\n",
    "        if max_value==min_value:\n",
    "            ### Still looking at a special case when max_value==min_value.\n",
    "            mys[k] = (mys[k]-min_value)\n",
    "        else:\n",
    "            if normalizedRanks: ### normalizedRanks is equal to fullnorm.\n",
    "                ### Then we normalized based on whether we have normalizedRanks or not.\n",
    "                mys[k] = (mys[k]-min_value) /(max_value-min_value)\n",
    "            else:\n",
    "                mys[k] = mys[k] /max_value \n",
    "\n",
    "    return(mys)   \n",
    " \n",
    "### Get updated reputations, new calculations of them...\n",
    "### This one is with log...\n",
    "\n",
    "def rater_reputation(previous_reputations,rater_id,default,prev_reputation,liquid=False,to_id = [],predictiveness = 0,predictive_data = dict()):\n",
    "    ### Assigning rater reputation. It is not trivial; if liquid=True, then we can expect that \n",
    "    if rater_id in previous_reputations.keys():\n",
    "        \n",
    "        ### Checks whether it's liquid or not. If liquid, return 1, otherwise previous reputation.\n",
    "        if (not liquid):\n",
    "            rater_rep = 1\n",
    "        else:\n",
    "            if rater_id in prev_reputation:\n",
    "                rater_rep = previous_reputations[rater_id] * 100\n",
    "            else:\n",
    "                rater_rep = previous_reputations[rater_id] * 100\n",
    "    else:\n",
    "\n",
    "        if (not liquid):\n",
    "            rater_rep = 1\n",
    "        else:\n",
    "            rater_rep = default * 100\n",
    "        ### If it is not in reputations up to the current one, we set a default value.\n",
    "\n",
    "    if predictiveness>0:\n",
    "        if rater_id not in predictive_data.keys():\n",
    "            pass # Do nothing\n",
    "            #raise ValueError('Calling for predictiveness without previous predictive data.')\n",
    "        else:\n",
    "            rater_rep = rater_rep * (1-predictiveness) + predictiveness * predictive_data[rater_id] * rater_rep\n",
    "    previous_rep1 = dict()\n",
    "    for k in prev_reputation.keys():\n",
    "        previous_rep1[k] = prev_reputation[k]\n",
    "    previous_rep1[rater_id] = rater_rep\n",
    "    return(rater_rep,previous_rep1)\n",
    "\n",
    "### Another normalization. This one is intended for reputation normalization.\n",
    "def normalize_reputation(reputation,new_array,unrated,default1,decay,conservatism,normalizedRanks=False):\n",
    "    max_value = max(reputation.values(), default=1)\n",
    "    min_value = min(reputation.values(), default=0)\n",
    "    ### First we make the same max/min values.\n",
    "    for k in reputation.keys():\n",
    "        if normalizedRanks: ### normalizedRanks is equal to fullnorm.\n",
    "            if max_value!=min_value:\n",
    "                reputation[k] = (reputation[k]-min_value) /(max_value-min_value)\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "        ### Now, way of solving this problem in a bit more common way:        \n",
    "            if max_value!= 0:\n",
    "                reputation[k] = reputation[k] /max_value\n",
    "            else:\n",
    "                pass\n",
    "    i = 0\n",
    "    ### if unrated=False, we discount new agents for conservativity and decay.\n",
    "    while i<len(new_array):\n",
    "        if unrated:\n",
    "            if new_array[i][0] in reputation.keys():\n",
    "                pass\n",
    "            else:\n",
    "                reputation[new_array[i][0]] = conservatism * default1 + (1-conservatism) * decay\n",
    "        i+=1\n",
    "    return(reputation)    \n",
    "    \n",
    "\n",
    "### Initialize dictionary with all keys from our dataset and 0 values;\n",
    "def initialize_dict(from_array,to_array):\n",
    "    mydict = {}\n",
    "    for k in np.unique(from_array):\n",
    "        if k in mydict.keys():\n",
    "            pass\n",
    "        ## If we do not have this record, we set it default reputation.\n",
    "        else:\n",
    "            mydict[str(k)] = 0\n",
    "    for k in np.unique(to_array):\n",
    "        if k in mydict.keys():\n",
    "            pass\n",
    "        ## If we do not have this record, we set it default reputation.\n",
    "        else:\n",
    "            mydict[str(k)] = 0\n",
    "    return(mydict)\n",
    "\n",
    "### Updating reputation - blending differential and reputation.\n",
    "### In original paper, there were a few proposed ways of updating and approach d has been found to be the most\n",
    "### useful and the only ne we are using at the moment.\n",
    "def update_reputation_approach_d(first_occurance,reputation,mys,since,our_date,default_rep,conservativity):\n",
    "    ### Our current approach of updating reputation each time period. \n",
    "    j = 0\n",
    "    all_keys = set(mys.keys())\n",
    "    for k  in reputation.keys():\n",
    "        if k in all_keys:\n",
    "            ### for everything inside reputation and differential, this is the equation we a reusing-\n",
    "            reputation[k] = (1-conservativity) * mys[k] + conservativity * reputation[k]\n",
    "        else:\n",
    "            ### when in reputation, but not in differential, this is what we do:\n",
    "            reputation[k] = (1-conservativity) * default_rep + conservativity * reputation[k]\n",
    "        j+=1  \n",
    "    return(reputation)\n",
    "\n",
    "\n",
    "\n",
    "### spendings_based function. So, we look at 'from' transactions and use the same calculation as \n",
    "### for normal differential, except that we use it for 'from' ids.\n",
    "def spending_based(transactions,som_dict,logratings,precision,weighting):\n",
    "    i=0\n",
    "    while i<len(transactions):\n",
    "        if transactions[i][0] in som_dict.keys():\n",
    "            if not weight_calc(transactions[i],logratings,precision,weighting)[1]==None:\n",
    "                som_dict[transactions[i][0]] += weight_calc(transactions[i],logratings,precision,weighting)[1]\n",
    "            else:\n",
    "                som_dict[transactions[i][0]] += weight_calc(transactions[i],logratings,precision,weighting)[0]\n",
    "                ### Not sure about above fix, but sometimes we have none value if weighting=False. This should fix it...\n",
    "        else:\n",
    "            if not weight_calc(transactions[i],logratings,precision,weighting)[1]==None:\n",
    "                som_dict[transactions[i][0]] = weight_calc(transactions[i],logratings,precision,weighting)[1]### changed from\n",
    "            #### new_rating instead of new_weight.\n",
    "            else:\n",
    "                som_dict[transactions[i][0]] = weight_calc(transactions[i],logratings,precision,weighting)[0]\n",
    "        i+=1\n",
    "    return(som_dict)\n",
    "\n",
    "### An alternative to np.where - created because sometimes there could be problems with former.\n",
    "def where(to_array,the_id):\n",
    "    our_ids = []\n",
    "    i=0\n",
    "    while i<len(to_array):\n",
    "        if to_array[i]==the_id:\n",
    "            our_ids.append(i)\n",
    "        i+=1\n",
    "    return(our_ids)\n",
    "\n",
    "### average_individual_rating_by_period\n",
    "def calculate_average_individual_rating_by_period(transactions,weighted):\n",
    "    count_trans = dict()\n",
    "    #if weighted:\n",
    "    ratings_avg = dict()\n",
    "    i = 0\n",
    "    while i<len(transactions):\n",
    "        if transactions[i][0] in ratings_avg.keys():\n",
    "            if transactions[i][1] in ratings_avg[transactions[i][0]].keys():\n",
    "                ratings_avg[transactions[i][0]][transactions[i][1]].append(transactions[i][3]) ### should be value append.\n",
    "                count_trans[transactions[i][0]][transactions[i][1]] += 1\n",
    "            else:\n",
    "                ratings_avg[transactions[i][0]][transactions[i][1]] = [transactions[i][3]]\n",
    "                count_trans[transactions[i][0]][transactions[i][1]] = 1\n",
    "        else:\n",
    "            ratings_avg[transactions[i][0]] = dict()\n",
    "            count_trans[transactions[i][0]] = dict()\n",
    "            ratings_avg[transactions[i][0]][transactions[i][1]] = [transactions[i][3]]\n",
    "            count_trans[transactions[i][0]][transactions[i][1]] = 1\n",
    "        i+=1\n",
    "    ### Now we make averages over everything.\n",
    "    for k in ratings_avg.keys():\n",
    "        for j in ratings_avg[k].keys():\n",
    "            ratings_avg[k][j] = np.mean(ratings_avg[k][j])\n",
    "    return(ratings_avg,count_trans)\n",
    "\n",
    "def max_date(mydict):\n",
    "    ### Get dictionary where keys are dates and we get the value of last date;\n",
    "    sorted_days = sorted(mydict.keys())\n",
    "    last_date = sorted_days[-1]\n",
    "    i = 0\n",
    "    return(mydict[last_date])\n",
    "\n",
    "### function of predictiveness\n",
    "def update_predictiveness_data(previous_pred,mydate,reputations,transactions,conservatism):\n",
    "    ids_used = []\n",
    "    for k in transactions:\n",
    "        from_id = k\n",
    "        ids_used.append(k)\n",
    "        if from_id not in previous_pred.keys():\n",
    "            previous_pred[from_id] = dict()\n",
    "        for to_id in transactions[from_id]:\n",
    "            if to_id in previous_pred[from_id].keys():\n",
    "                previous_pred[from_id][to_id] = transactions[from_id][to_id] * (1-conservatism) + conservatism * previous_pred[from_id][to_id] ### mydate should not exist yet in our run.\n",
    "            else:\n",
    "                previous_pred[from_id][to_id] = dict()\n",
    "                previous_pred[from_id][to_id] = transactions[from_id][to_id] #\n",
    "    return(previous_pred,ids_used)\n",
    "\n",
    "def normalize_individual_data(mydate,new_ids):\n",
    "    all_from = new_ids.keys()\n",
    "    max_values = dict()\n",
    "    for k in all_from.keys():\n",
    "        max_values[k] = []\n",
    "        for j in all_from[k].keys():\n",
    "            if mydate in all_from[k][j].keys():\n",
    "                max_values.append(all_from[k][j][mydate])\n",
    "        \n",
    "        ### ok, now we've added values to max_values. We continue with another, similar loop;\n",
    "        max_value = max(max_values)\n",
    "        for j in all_from[k].keys():\n",
    "            if mydate in all_from[k][j].keys():\n",
    "                all_from[k][j][mydate] = all_from[k][j][mydate]/max_values\n",
    "\n",
    "                \n",
    "def calculate_distance(previous_individual_rating,curret_reputation_rank):\n",
    "    distance = 0\n",
    "    j = 0\n",
    "    while j<len(previous_individual_rating):\n",
    "        distance += (curret_reputation_rank[j]/1 - previous_individual_rating[j]/1)**2\n",
    "        j+=1\n",
    "    distance = distance/len(previous_individual_rating)\n",
    "    return(np.sqrt(distance))\n",
    "\n",
    "def normalize_correlations(mydict):\n",
    "    mymax = max(mydict.values())\n",
    "    for k in mydict.keys():\n",
    "        mydict[k] = mydict[k]/mymax\n",
    "    return(mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reputation Scenario:\n",
    "\n",
    "\n",
    "\n",
    "# Simulation Reputation Scenario Data Generator\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "network = 'reptest'\n",
    "\n",
    "# percents of goodness for agent to be selected by consumer, 0 to select all, 100 or None to select only the top\n",
    "#threshold = 10 # for \"10 agents X 10 days\", that is too low - bad agents still get chance to be selected on days 2 and 3\n",
    "#threshold = 50 # for \"10 agents X 10 days\", that is too high - one good agent gets associated with bad agents\n",
    "threshold = 40\n",
    "\n",
    "def list_best_ranked(ranks,list,threshold=None):\n",
    "\tif threshold is None:\n",
    "\t\tthreshold = 0\n",
    "\t\tfor key in ranks:\n",
    "\t\t\tvalue = ranks[key]\n",
    "\t\t\tif threshold < value:\n",
    "\t\t\t\t threshold = value\n",
    "\tif threshold == 0:\n",
    "\t\treturn list\n",
    "\tbest = []\n",
    "\tfor item in list:\n",
    "\t\tkey = str(item)\n",
    "\t\tif key in ranks:\n",
    "\t\t\tvalue = ranks[key]\n",
    "\t\t\tif threshold <= value:\n",
    "\t\t\t\t best.append(item)\n",
    "\tif len(best) == 0:\n",
    "\t\treturn list\n",
    "\treturn best\n",
    "\n",
    "def intersection(lst1, lst2): \n",
    "\tlst3 = [value for value in lst1 if value in lst2] \n",
    "\treturn lst3\n",
    "\n",
    "def pick_agent(ranks,list,self,memories = None,bad_agents = None):\n",
    "\tpicked = None\n",
    "\tif memories is not None:\n",
    "\t\t#good agents case\n",
    "\t\tif self in memories:\n",
    "\t\t\tblacklist = memories[self]\n",
    "\t\telse:\n",
    "\t\t\tblacklist = []\n",
    "\t\t\tmemories[self] = blacklist\n",
    "\t\tif blacklist is not None:\n",
    "\t\t\tlist = [white for white in list if white not in blacklist and white != self]\n",
    "\t\tif ranks is not None:\n",
    "\t\t\tlist = list_best_ranked(ranks,list,threshold)\n",
    "\telse:\n",
    "\t\t#bad agents case\n",
    "\t\tblacklist = None\n",
    "\t\tlist = [black for black in list if black != self]\n",
    "\tpicked = list[0] if len(list) == 1 else list[random.randint(0,len(list)-1)]\n",
    "\n",
    "\t#debug\n",
    "\t#if blacklist is not None:\n",
    "\t#\tprint(picked)\n",
    "\t\n",
    "\tif blacklist is not None and bad_agents is not None and picked in bad_agents:\n",
    "\t\tblacklist.append(picked) #blacklist picked bad ones once picked so do not pick them anymore\n",
    "\treturn picked\n",
    "\n",
    "\n",
    "def log_file(file,date,type,agent_from,agent_to,cost,rating):\n",
    "\ttimestr = str(time.mktime(date.timetuple()))\n",
    "\ttimestr = timestr[:-2] # trim .0 part\n",
    "\tfile.write(network + '\\t' + timestr + '\\t' + type + '\\t' + str(agent_from) + '\\t' + str(agent_to) + '\\t' + str(cost) + '\\t' \\\n",
    "\t\t\t+ '\\t\\t\\t\\t\\t\\t\\t\\t' + ('' if rating is None else str(rating)) + '\\t\\n')\n",
    "\n",
    "\n",
    "def get_list_fraction(list,fraction,first):\n",
    "\tn = round (len(list) * (fraction if first else 1 - fraction))\n",
    "\tres_list = list[:n] if first else list[n:]\n",
    "\treturn res_list\n",
    "\n",
    "\n",
    "def reputation_simulate(good_agent,bad_agent,since,sim_days,ratings,rs,verbose=False,campaign=None,silent=False):\n",
    "\trandom.seed(1) # Make it deterministic\n",
    "\tmemories = {} # init blacklists of compromised ones\n",
    "\n",
    "\tif rs is not None:\n",
    "\t\trs.clear_ratings()\n",
    "\t\trs.clear_ranks()\n",
    "\n",
    "\tactual_bad_volume = 0\n",
    "\tactual_good_volume = 0\n",
    "\tactual_good_to_bad_volume = 0\n",
    "\t\n",
    "\tgood_agents = [i for i in range(good_agent['range'][0],good_agent['range'][1]+1)]\n",
    "\tbad_agents = [i for i in range(bad_agent['range'][0],bad_agent['range'][1]+1)]\n",
    "\n",
    "\tgood_suppliers = get_list_fraction(good_agents,good_agent['suppliers'],True)\n",
    "\tbad_suppliers = get_list_fraction(bad_agents,bad_agent['suppliers'],True)\n",
    "\tgood_consumers = get_list_fraction(good_agents,good_agent['consumers'],False)\n",
    "\tbad_consumers = get_list_fraction(bad_agents,bad_agent['consumers'],False)\n",
    "\tall_suppliers = good_suppliers + bad_suppliers\n",
    "\tall_consumers = good_consumers + bad_consumers\n",
    "\tall_agents = good_agents + bad_agents\n",
    "\n",
    "\tif verbose:\n",
    "\t\tprint('Good:',good_agent)\n",
    "\t\tprint('Bad:',bad_agent)\n",
    "\t\tprint('Good:',good_agents)\n",
    "\t\tprint('Bad:',bad_agents)\n",
    "\t\tprint('All suppliers:',all_suppliers)\n",
    "\t\tprint('All consumers:',all_consumers)\n",
    "\t\tprint('Good suppliers:',good_suppliers)\n",
    "\t\tprint('Good consumers:',good_consumers)\n",
    "\t\tprint('Bad suppliers:',bad_suppliers)\n",
    "\t\tprint('Bad consumers:',bad_consumers)\n",
    "\t\n",
    "\tgood_agents_transactions = good_agent['transactions']\n",
    "\tbad_agents_transactions = bad_agent['transactions']\n",
    "\tgood_agents_values = good_agent['values']\n",
    "\tbad_agents_values = bad_agent['values']\n",
    "\tgood_agents_count = len(good_agents)\n",
    "\tbad_agents_count = len(bad_agents)\n",
    "\tgood_agents_volume = good_agents_count * good_agents_transactions * good_agents_values[0]\n",
    "\tbad_agents_volume = bad_agents_count * bad_agents_transactions * bad_agents_values[0]\n",
    "\tcode = ('r' if ratings else 'p') + '_' + str(round(good_agents_values[0]/bad_agents_values[0])) + '_' + str(good_agents_transactions/bad_agents_transactions) \\\n",
    "\t\t+ (('rs' if rs.get_parameters()['weighting'] == True else 'nw') if rs is not None else '') \n",
    "\ttransactions = 'transactions' + str(len(all_agents)) + '_' + code + '.tsv'\n",
    "\t\n",
    "\tif verbose:\n",
    "\t\tprint('Good:',len(good_agents),good_agents_values[0],good_agents_transactions,len(good_agents)*good_agents_values[0]*good_agents_transactions)\n",
    "\t\tprint('Bad:',len(bad_agents),bad_agents_values[0],bad_agents_transactions,len(bad_agents)*bad_agents_values[0]*bad_agents_transactions)\n",
    "\t\tprint('Code:',code,'Volume ratio:',str(good_agents_volume/bad_agents_volume))\n",
    "\n",
    "\twith open(transactions, 'w') as file:\n",
    "\t\tfor day in range(sim_days):\n",
    "\t\t\tprev_date = since + datetime.timedelta(days=(day-1))\n",
    "\t\t\tdate = since + datetime.timedelta(days=day)\n",
    "\t\t\tif verbose:\n",
    "\t\t\t\tprint(day,date,memories)\n",
    "\n",
    "\t\t\tif rs is not None:\n",
    "\t\t\t\t#update ranks for the previous day to have them handy\n",
    "\t\t\t\trs.update_ranks(prev_date)\n",
    "\t\t\t\tranks = rs.get_ranks_dict({'date':prev_date})\n",
    "\t\t\t\tif verbose:\n",
    "\t\t\t\t\tprint('Ranks',ranks)\n",
    "\t\t\telse:\n",
    "\t\t\t\tranks = None\n",
    "\n",
    "\t\t\t#resetting scam campaign\n",
    "\t\t\tskip_scam = False\n",
    "\t\t\tif campaign is not None:\n",
    "\t\t\t\tcampaign_day = day % campaign[0] # campaign.period\n",
    "\t\t\t\tif campaign_day == 0:\n",
    "\t\t\t\t\tif day > 0:\n",
    "\t\t\t\t\t\tif verbose:\n",
    "\t\t\t\t\t\t\tprint('reset scam')\n",
    "\t\t\t\t\t\tscam_generation = day // campaign[0] # campaign.period\n",
    "\t\t\t\t\t\tid_base = len(bad_agents) * scam_generation\n",
    "\t\t\t\t\t\tbad_agents = [i+id_base for i in range(bad_agent['range'][0],bad_agent['range'][1]+1)]\n",
    "\t\t\t\t\t\tbad_suppliers = get_list_fraction(bad_agents,bad_agent['suppliers'],True)\n",
    "\t\t\t\t\t\tbad_consumers = get_list_fraction(bad_agents,bad_agent['consumers'],False)\n",
    "\t\t\t\t\t\tall_suppliers = good_suppliers + bad_suppliers\n",
    "\t\t\t\t\tif verbose:\n",
    "\t\t\t\t\t\tprint('bad agents:',bad_agents)\n",
    "\t\t\t\tif campaign_day < campaign[1]: # campaign.inactive\n",
    "\t\t\t\t\tif verbose:\n",
    "\t\t\t\t\t\tprint('skip scam')\n",
    "\t\t\t\t\tskip_scam = True\n",
    "\t\t\t\tif verbose:\n",
    "\t\t\t\t\tprint('do scam')\n",
    "\n",
    "\t\t\tdaily_good_to_bad = 0\n",
    "\t\t\tfor agent in good_consumers:\n",
    "\t\t\t\tdaily_selections = {}\n",
    "\t\t\t\tfor t in range(0, good_agents_transactions):\n",
    "\t\t\t\t\tother = pick_agent(ranks,all_suppliers,agent,memories,bad_agents)\n",
    "\t\t\t\t\tcost = random.randint(good_agents_values[0],good_agents_values[1])\n",
    "\t\t\t\t\tactual_good_volume += cost\n",
    "\t\t\t\t\t# while ratings range is [0.0, 0.25, 0.5, 0.75, 1.0], we rank good agents as [0.25, 0.5, 0.75, 1.0]\n",
    "\t\t\t\t\trating = 0.0 if other in bad_agents else float(random.randint(1,4))/4\n",
    "\t\t\t\t\tif other in bad_agents:\n",
    "\t\t\t\t\t\tactual_good_to_bad_volume += cost\n",
    "\t\t\t\t\t\tdaily_good_to_bad += cost\n",
    "\t\t\t\t\tif ratings:\n",
    "\t\t\t\t\t\tif rs is not None:\n",
    "\t\t\t\t\t\t\trs.put_ratings([{'from':agent,'type':'rating','to':other,'value':rating,'weight':cost,'time':date}])\n",
    "\t\t\t\t\t\tlog_file(file,date,'rating',agent,other,rating,cost)\n",
    "\t\t\t\t\telse: \n",
    "\t\t\t\t\t\tif rs is not None:\n",
    "\t\t\t\t\t\t\trs.put_ratings([{'from':agent,'type':'transfer','to':other,'value':cost,'time':date}])\n",
    "\t\t\t\t\t\tlog_file(file,date,'transfer',agent,other,cost,None)\n",
    "\t\t\t\t\tdaily_selections[other] = 1 + daily_selections[other] if other in daily_selections else 1\n",
    "\t\t\t\tif verbose:\n",
    "\t\t\t\t\tprint('By ' + str(agent) + ':' + str(daily_selections))\n",
    "\n",
    "\t\t\tif verbose:\n",
    "\t\t\t\tprint(daily_good_to_bad)\n",
    "\n",
    "\t\t\tif skip_scam:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\n",
    "\t\t\tfor agent in bad_consumers:\n",
    "\t\t\t\tfor t in range(0, bad_agents_transactions):\n",
    "\t\t\t\t\tother = pick_agent(None,bad_suppliers,agent)\n",
    "\t\t\t\t\tcost = random.randint(bad_agents_values[0],bad_agents_values[1])\n",
    "\t\t\t\t\tactual_bad_volume += cost\n",
    "\t\t\t\t\tif ratings:\n",
    "\t\t\t\t\t\trating = 1.0\n",
    "\t\t\t\t\t\tif rs is not None:\n",
    "\t\t\t\t\t\t\trs.put_ratings([{'from':agent,'type':'rating','to':other,'value':rating,'weight':cost,'time':date}])\n",
    "\t\t\t\t\t\tlog_file(file,date,'rating',agent,other,rating,cost)\n",
    "\t\t\t\t\telse: \n",
    "\t\t\t\t\t\tif rs is not None:\n",
    "\t\t\t\t\t\t\trs.put_ratings([{'from':agent,'type':'transfer','to':other,'value':cost,'time':date}])\n",
    "\t\t\t\t\t\tlog_file(file,date,'transfer',agent,other,cost,None)\n",
    "\t\t\t\t\t\n",
    "\twith open('users' + str(len(all_agents)) + '.tsv', 'w') as file:\n",
    "\t\tfor agent in all_agents:\n",
    "\t\t\tgoodness = '0' if agent in bad_agents else '1'\n",
    "\t\t\tfile.write(str(agent) + '\\t' + goodness + '\\n')\n",
    "\n",
    "\tif verbose:\n",
    "\t\tprint('Actual volumes and ratios:')\n",
    "\n",
    "\tdef ratio_str(x,y):\n",
    "\t\treturn 'INF' if y == 0 else x/y\n",
    "\t\t\n",
    "\tif silent is not True:\n",
    "\t\tprint('Good:',str(actual_good_volume),'Bad:',str(actual_bad_volume),'Good to Bad:',actual_good_to_bad_volume,'Good/Bad:',ratio_str(actual_good_volume,actual_bad_volume),'Bad/Good_to_Bad:',ratio_str(actual_bad_volume,actual_good_to_bad_volume),'LTS:',ratio_str(actual_good_to_bad_volume,actual_good_volume),'PFS:',ratio_str(actual_good_to_bad_volume,actual_bad_volume))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reputation Service API, including Rating Service and Ranking Service\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from datetime import datetime, timedelta,date\n",
    "#from reputation_base_api import ReputationServiceBase\n",
    "import logging as logging\n",
    "\n",
    "\"\"\"\n",
    "Reputation Service native implementation in Python\n",
    "\"\"\"  \n",
    "\n",
    "\n",
    "class PythonReputationService(ReputationServiceBase):\n",
    "    \n",
    "    ### This function allows us to set up the parameters.\n",
    "    ### Setting up the way we do in Anton's recommendation.\n",
    "    ### update_period is how many days we jump in one period... We can adjust it...\n",
    "\n",
    "    ### Set parameters. In changes, there is a dictionary with values and if there are no determined values,\n",
    "    ### we set up default values.\n",
    "    def set_parameters(self,changes):\n",
    "        if 'default' in changes.keys():\n",
    "            self.default = changes['default']\n",
    "        else:\n",
    "            if 'default' in dir(self):\n",
    "                pass\n",
    "            else:\n",
    "                self.default = 0.5 # default value \n",
    "        if 'conservatism' in changes.keys():\n",
    "            self.conservatism = changes['conservatism']\n",
    "        else:\n",
    "            if 'conservatism' in dir(self):\n",
    "                pass\n",
    "            else:\n",
    "                self.conservatism = 0.5\n",
    "        if 'precision' in changes.keys():\n",
    "            self.precision = changes['precision']\n",
    "        else:\n",
    "            if 'precision' in dir(self):\n",
    "                pass\n",
    "            else:\n",
    "                self.precision = 0.01\n",
    "        if 'weighting' in changes.keys():\n",
    "            self.weighting = changes['weighting']\n",
    "        else:\n",
    "            if 'weighting' in dir(self):\n",
    "                pass\n",
    "            else:\n",
    "                self.weighting = True\n",
    "        if 'denomination' in changes.keys():\n",
    "            self.denomination = changes['denomination']\n",
    "        else:\n",
    "            if 'denomination' in dir(self):\n",
    "                pass\n",
    "            else:\n",
    "                self.denomination = False\n",
    "        if 'fullnorm' in changes.keys():\n",
    "            self.fullnorm = changes['fullnorm']\n",
    "        else:\n",
    "            if 'fullnorm' in dir(self):\n",
    "                pass\n",
    "            else:\n",
    "                self.fullnorm = True\n",
    "        if 'liquid' in changes.keys():\n",
    "            self.liquid = changes['liquid']\n",
    "        else:\n",
    "            if 'liquid' in dir(self):\n",
    "                pass\n",
    "            else:\n",
    "                self.liquid = True\n",
    "        if 'logranks' in changes.keys():\n",
    "            self.logranks = changes['logranks']\n",
    "        else:\n",
    "            if 'logranks' in dir(self):\n",
    "                pass\n",
    "            else:\n",
    "                self.logranks = True\n",
    "        if 'update_period' in changes.keys():\n",
    "            self.update_period = changes['update_period']\n",
    "        else:\n",
    "            if 'update_period' in dir(self):\n",
    "                pass\n",
    "            else:\n",
    "                self.update_period = 1\n",
    "        if 'logratings' in changes.keys():\n",
    "            self.logratings = changes['logratings']\n",
    "        else:\n",
    "            if 'logratings' in dir(self):\n",
    "                pass\n",
    "            else:\n",
    "                self.logratings = False\n",
    "        if 'temporal_aggregation' in changes.keys():\n",
    "            self.temporal_aggregation = changes['temporal_aggregation']\n",
    "        else:\n",
    "            if 'temporal_aggregation' in dir(self):\n",
    "                pass\n",
    "            else:\n",
    "                self.temporal_aggregation = False\n",
    "        if 'use_ratings' in changes.keys():\n",
    "            self.use_ratings = changes['use_ratings']\n",
    "        else:\n",
    "            if 'use_ratings' in dir(self):\n",
    "                pass\n",
    "            else:\n",
    "                self.use_ratings = True\n",
    "        if 'start_date' in changes.keys():\n",
    "            start_date = changes['start_date']\n",
    "            self.date = start_date\n",
    "        else:\n",
    "            if 'date' in dir(self):\n",
    "                pass\n",
    "            else:\n",
    "                self.date = date(2018, 1, 1)       \n",
    "        if 'first_occurance' in changes.keys():\n",
    "            self.first_occurance = changes['first_occurance']\n",
    "        else:\n",
    "            if 'first_occurance' in dir(self):\n",
    "                pass\n",
    "            else:\n",
    "                self.first_occurance = {}\n",
    "        if 'decayed' in changes.keys():\n",
    "            self.decayed = changes['decayed']\n",
    "        else:\n",
    "            if 'decayed' in dir(self):\n",
    "                pass\n",
    "            else:\n",
    "                self.decayed = 0\n",
    "        if 'downrating' in changes.keys():\n",
    "            self.downrating = changes['downrating']\n",
    "        else:\n",
    "            self.downrating = False   \n",
    "        if 'unrated' in changes.keys():\n",
    "            self.unrated = changes['unrated']\n",
    "        else:\n",
    "            self.unrated = False   \n",
    "        if 'spendings' in changes.keys():\n",
    "            self.spendings = changes['spendings']\n",
    "        else:\n",
    "            self.spendings = 0.0   \n",
    "        if 'ratings' in changes.keys():\n",
    "            self.ratings_param = changes['ratings']\n",
    "        else:\n",
    "            self.ratings_param = 1.0      \n",
    "        if 'rating_bias' in changes.keys():\n",
    "            self.rating_bias = changes['rating_bias']\n",
    "        else:\n",
    "            self.rating_bias = False\n",
    "        if 'predictiveness' in changes.keys():\n",
    "            self.predictiveness = changes['predictiveness']\n",
    "        else:\n",
    "            self.predictiveness = 0   \n",
    "        if 'logging' in changes.keys():\n",
    "            self.logging = changes['logging']\n",
    "        else:\n",
    "            self.logging = True              \n",
    "        if self.logging: ### If logging is enabled, we log everything\n",
    "            log_name = \"python-log\" + datetime.datetime.now().strftime('%Y-%m-%d') + \"-log.log\"\n",
    "            logging.basicConfig(filename=log_name, filemode='w', format='%(name)s - %(levelname)s - %(asctime)s - %(message)s', level=10)\n",
    "            logging.info('We start our system.')\n",
    "        else:### If logging is disabled, we log only critical messages or higher priority messages.\n",
    "            log_name = \"python-log_critical\" + datetime.datetime.now().strftime('%Y-%m-%d') + \"-log.log\"\n",
    "            logging.basicConfig(filename=log_name, filemode='w', format='%(name)s - %(levelname)s - %(asctime)s - %(message)s',level=logging.CRITICAL)\n",
    "            logging.disable(logging.CRITICAL)\n",
    "            logging.info('We start our system.') \n",
    "        text = \"set parameters default \" + str(self.default) + \", decayed \" + str(self.decayed) + \", conservatism \"+str(self.conservatism) + \", precision \" + str(self.precision) + \", liquid \"+str(self.liquid) + \", update_period \" + str(self.update_period) + \", aggregation \" + str(self.temporal_aggregation) + \", downrating \" + str(self.downrating) + \", fullnorm \" + str(self.fullnorm) + \", weighting \" + str(self.weighting) + \", denomination \" + str(self.denomination) + \", logratings \" + str(self.logratings) + \", ratings \" + str(self.ratings_param) + \", spendings \" + str(self.spendings) + \", predictiveness \" + str(self.predictiveness) + \", unrated \" + str(self.unrated) + \", rating_bias \" + str(self.rating_bias) + \", logranks \" + str(self.logranks)\n",
    "        logging.debug(text)    \n",
    "        return(0)\n",
    "        \n",
    "    ### This functions merely displays the parameters.\n",
    "    def get_parameters(self):              \n",
    "        return({'default': self.default,'decayed':self.decayed, 'conservatism':self.conservatism, 'precision':self.precision,\n",
    "                'liquid':self.liquid,'update_period':self.update_period,'aggregation':self.temporal_aggregation,\n",
    "                'downrating':self.downrating,'fullnorm':self.fullnorm, 'weighting':self.weighting,'denomination':self.denomination,\n",
    "                'logratings':self.logratings, 'ratings':self.ratings_param, 'spendings':self.spendings,'predictiveness':self.predictiveness,'unrated':self.unrated,'rating_bias':self.rating_bias,'logranks':self.logranks})\n",
    "#27:body:2019-07-30T23:53:21.511:I:8c5b4f5fb913462e99c248daccfc36c0:reputation network test set parameters default 0.5 decayed 0.5 conservatism 0.25 precision 0.01 liquid true period 1 aggregation true downrating false fullnorm false weighting true denomination false logratings false ratings 1.0 spendings 0.0 parents 0.0 predictiveness 1 rating_bias true unrated false\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## Update date\n",
    "    def set_date(self,newdate):\n",
    "        self.our_date = newdate\n",
    "    ### Clear stored reputations.    \n",
    "    def clear_ranks(self):\n",
    "        self.reputation = {}   \n",
    "        self.all_reputations = {}\n",
    "        self.predictive_data = dict()\n",
    "        self.pred_values = dict()\n",
    "        self.count_values = dict()\n",
    "        logging.debug('Ranks cleared.')\n",
    "        return(0)\n",
    "    ### Clear stored ratings (transactions).\n",
    "    def clear_ratings(self):\n",
    "        self.ratings = {}\n",
    "        logging.debug('Ratings cleared.')\n",
    "        return(0)\n",
    "    ### Initialization of reputation.    \n",
    "    def initialize_ranks(self,reputation=None,first_occurance = None):\n",
    "        ### First, we check if there is a reputation dictionary (where ranks should be stored) and if not, create one.\n",
    "        if reputation==None:\n",
    "            self.reputation = dict()\n",
    "        else:\n",
    "            self.reputation = reputation      \n",
    "    ### get all dates that we have in stored ratings. This is how we can store them in self.dates.\n",
    "    def all_dates(self):\n",
    "        i = 0\n",
    "        all_dates = []\n",
    "        while i<len(self.ratings):\n",
    "            if self.ratings[i]['time'] in all_dates:\n",
    "                pass\n",
    "            else:\n",
    "                all_dates.append(self.ratings[i]['time'])\n",
    "            i+=1\n",
    "        self.dates = all_dates\n",
    "    ### select ratings from selected update period (whichever it is set).\n",
    "    def select_data(self,mydate):\n",
    "        min_date = mydate - timedelta(days=self.update_period) # We look today minus update_period number of days.\n",
    "        max_date = mydate\n",
    "        i=0\n",
    "        while i<len(self.ratings):\n",
    "            mydict = self.ratings[i]\n",
    "            if type(mydict) is list:\n",
    "                mydict = mydict[0]\n",
    "            if (mydict['time'] > min_date and mydict['time']<=max_date): ## If in right ime period, then we add it to\n",
    "                ### current_ratings. Which we analyze.\n",
    "                self.current_ratings.append(mydict)\n",
    "            i+=1\n",
    "   \n",
    "    ### We can also convert data from pandas to dictionary.\n",
    "    def convert_data(self,data):\n",
    "        daily_data = data[['from','type','to','weight','time','value','type']].to_dict(\"records\")\n",
    "        self.all_dates()\n",
    "        i = 0\n",
    "        while i<len(daily_data):\n",
    "            daily_data[i]['from'] = str(daily_data[i]['from'])# the only thing we make sure is that\n",
    "            # 'from' and 'to' are strings.\n",
    "            daily_data[i]['to'] = str(daily_data[i]['to'])\n",
    "            i+=1\n",
    "        self.ratings = daily_data\n",
    "        return(daily_data)\n",
    "\n",
    "    ### We run the update in this function.    \n",
    "    def update_ranks(self,mydate):\n",
    "        if not \"rater_ranks_special\" in dir(self):\n",
    "            self.rater_ranks_special = dict()\n",
    "        self.non_rounded_rep = dict()\n",
    "        text = \"period \" +  str(self.update_period)\n",
    "        logging.debug(text)\n",
    "        ### And then we iterate through functions. First we prepare arrays and basic computations.\n",
    "        since = mydate - timedelta(days=self.update_period)\n",
    "        if self.rating_bias:\n",
    "            if 'rater_biases' in dir(self):\n",
    "                pass\n",
    "            else:\n",
    "                self.rater_biases = dict()\n",
    "                self.rater_biases[since] = dict()\n",
    "        if self.predictiveness>0:\n",
    "            if 'predictive_data' in dir(self):\n",
    "                pass\n",
    "            else:\n",
    "                self.predictive_data = dict()\n",
    "                self.pred_values = dict()\n",
    "                self.count_values = dict()\n",
    "                \n",
    "        self.current_ratings = []\n",
    "        ### Sellect data which we will use.\n",
    "        self.select_data(mydate)\n",
    "        i=0\n",
    "        problem = False\n",
    "        while i<len(self.current_ratings):\n",
    "            ### If we do not have values, then we have a problem. Even if only one rating is missing,\n",
    "            ### there is a problem.\n",
    "            if (self.use_ratings==True and (not 'value' in self.current_ratings[i].keys())):\n",
    "                problem=True\n",
    "            i+=1\n",
    "        if problem:\n",
    "            ### Well, if we have a problem, we just set ratings to false. Code will still work.\n",
    "            logging.warning(\"Ratings is set to True, but no ratings were given. Changing the setting to False\")\n",
    "            self.use_ratings=False\n",
    "        problem = False \n",
    "        ### if we have some ratings, we can check;\n",
    "        if len(self.current_ratings)>0:\n",
    "            ### If we have payments and downratings to true, there is a small error.\n",
    "            if (self.current_ratings[0]['type']==\"payment\" and self.downrating==True):\n",
    "                ### raising error message.\n",
    "                warnings.warn(\"if we only have payments, we have no ratings. Therefore downratings cannot be True. Setting them to False\") \n",
    "                self.downrating=False\n",
    "        ### we set up arrays; this is the set of data where we have ratings, values, weights\n",
    "        ### in predictable way, so we can iterate them later on.\n",
    "        if self.rating_bias:\n",
    "            if 'average_ratings' in dir(self):\n",
    "                pass\n",
    "            else:\n",
    "                self.average_ratings = dict()\n",
    "            self.rater_biases[mydate] = dict()\n",
    "            array1 , dates_array, to_array, rater_biases1, avgs = reputation_calc_p1(self.current_ratings,self.conservatism,self.precision,self.temporal_aggregation,False,self.logratings,self.downrating,self.weighting,self.rater_biases[since],self.average_ratings)\n",
    "            self.average_ratings[mydate] = avgs\n",
    "            self.rater_biases[mydate] = dict(rater_biases1)\n",
    "        else:\n",
    "            array1 , dates_array, to_array, rater_biases1 = reputation_calc_p1(self.current_ratings,self.conservatism,self.precision,self.temporal_aggregation,False,self.logratings,self.downrating,self.weighting, None)  ### In this case, we don't need rater_biases\n",
    "        ### Now we update the reputation. Here, old ranings are inseter and then new ones are calculated as output.\n",
    "\n",
    "        self.reputation = update_reputation(self.reputation,array1,self.default,self.spendings)\n",
    "        \n",
    "        \n",
    "        ### If we have spendings-based reputation, we go in the loop below.\n",
    "        if self.spendings>0:\n",
    "            spendings_dict = spending_based(array1,dict(),self.logratings,self.precision,self.weighting)\n",
    "            ### We normalize differential that is spendings-based.\n",
    "            spendings_dict = normalized_differential(spendings_dict,normalizedRanks=self.fullnorm,our_default=self.default,spendings=self.spendings,log=self.logranks)     \n",
    "        \n",
    "        ### Then we calculate differential the normal way.\n",
    "        if self.predictiveness>0:\n",
    "            new_reputation,self.rater_ranks_special = calculate_new_reputation(logging = logging,new_array = array1,to_array = to_array,reputation = self.reputation,rating = self.use_ratings,precision = self.precision,previous_rep = self.rater_ranks_special,default=self.default,unrated=self.unrated,normalizedRanks=self.fullnorm,weighting = self.weighting,denomination = self.denomination, liquid = self.liquid, logratings = self.logratings,logranks = self.logranks, predictiveness = self.predictiveness,predictive_data = self.pred_values)\n",
    "        else:\n",
    "            new_reputation,self.rater_ranks_special = calculate_new_reputation(logging = logging,new_array = array1,to_array = to_array,reputation = self.reputation,rating = self.use_ratings,precision = self.precision,previous_rep = self.rater_ranks_special,default=self.default,unrated=self.unrated,normalizedRanks=self.fullnorm,weighting = self.weighting,denomination = self.denomination, liquid = self.liquid, logratings = self.logratings,logranks = self.logranks, predictiveness = self.predictiveness)\n",
    "        ### And then we normalize the differential:\n",
    "        new_reputation = normalized_differential(new_reputation,normalizedRanks=self.fullnorm,our_default=self.default,spendings=self.spendings,log=False)\n",
    "        text = \"Normalized differential: \" + str(new_reputation)\n",
    "        logging.debug(text)  \n",
    "        ### Again only starting this loop if we have spendings.\n",
    "        ### we take data from date-update_period.\n",
    "        ### For spendings-based system. We store all agents' reputations and then we only show reputations of\n",
    "        ### sellers when get_ranks() is called. This is not in line with Java implementation, which only returns\n",
    "        ### sellers. To circumvent that, we make an object in which we store only sellers and we then return only sellers.\n",
    "        ### We still need all ranks, so they are still stored in self.all_reputations\n",
    "        \n",
    "        if \"sellers\" in dir(self):\n",
    "            pass\n",
    "        else:\n",
    "            self.sellers = []\n",
    "        \n",
    "        for k in new_reputation.keys():\n",
    "            if k not in self.sellers:\n",
    "                self.sellers.append(k)\n",
    "        if (self.spendings>0 and self.predictiveness==0):\n",
    "            updated_differential = dict()\n",
    "            unique_keys = list(new_reputation.keys())\n",
    "            ###  each 'from' is added to unique_keys list. We add it to what is already in differential.\n",
    "            for k in spendings_dict.keys():\n",
    "                if not k in unique_keys:\n",
    "                    unique_keys.append(k)\n",
    "            for k in unique_keys:\n",
    "                ### Then we have different cases of what happens depending on where we have a certain key.\n",
    "                if (k in new_reputation.keys()) and (k in spendings_dict.keys()):\n",
    "                    ### Note, everything is already nomalized. The rest are just the equations to make sure everything is correct.\n",
    "                    updated_differential[k] = (self.ratings_param * new_reputation[k] + self.spendings * spendings_dict[k])/ (self.spendings + self.ratings_param)\n",
    "                if (k in new_reputation.keys()) and (k not in spendings_dict.keys()): \n",
    "                    updated_differential[k] = (self.ratings_param * new_reputation[k])/ (self.spendings + self.ratings_param)\n",
    "                if (k not in new_reputation.keys()) and (k in spendings_dict.keys()): \n",
    "                    updated_differential[k] = (self.spendings * spendings_dict[k])/ (self.spendings + self.ratings_param)\n",
    "            ### Differential is then from both spendings and usual differential.\n",
    "            new_reputation = updated_differential\n",
    "        # THen we blend the reputation with differential.\n",
    "        self.reputation = update_reputation_approach_d(self.first_occurance,self.reputation,new_reputation,since,\n",
    "                                                       self.date, self.decayed,self.conservatism)\n",
    "        ### Apply normalizedRanks=True AKA \"full normalization\" to prevent negative ratings on \"downrating\"\n",
    "        ### See line 360 in https://github.com/aigents/aigents-java/blob/master/src/main/java/net/webstructor/peer/Reputationer.java\n",
    "        ### and line 94 in https://github.com/aigents/aigents-java/blob/master/src/main/java/net/webstructor/data/Summator.java \n",
    "        ### Downratings seem to pass, so I assume this comment is resolved.\n",
    "        text = \"Blended differential with reputation: \" + str(self.reputation)\n",
    "        logging.debug(text) \n",
    "        self.reputation = normalize_reputation(self.reputation,array1,self.unrated,self.default,self.decayed,self.conservatism,self.downrating)\n",
    "        self.non_rounded_rep = dict(self.reputation)\n",
    "        ### round reputations:\n",
    "        for k in self.reputation.keys():\n",
    "            self.reputation[k] = my_round(self.reputation[k],2) # Make sure we use my_round. \n",
    "            ### This might be changed in the future, but now rounding is done in order to be the same as in Java rs.\n",
    "        ## We have all_reputations dictionary where we have all history of reputations with dates as keys.\n",
    "        text = \"Normalized reputation: \" + str(self.reputation)\n",
    "        logging.debug(text)\n",
    "        self.all_reputations[mydate] = dict(self.reputation)\n",
    "        if self.predictiveness>0:\n",
    "            avg_ind_rat_byperiod,self.count_values[mydate] = calculate_average_individual_rating_by_period(array1,True)\n",
    "            text = \"Average individual rating by period: \" + str(avg_ind_rat_byperiod)\n",
    "            logging.debug(text)\n",
    "            #self.predictive_data, ids = update_predictiveness_data(self.predictive_data,mydate,self.reputation,avg_ind_rat_byperiod,self.conservatism)\n",
    "            self.predictive_data, ids = update_predictiveness_data(self.predictive_data,mydate,self.reputation,avg_ind_rat_byperiod,self.conservatism)\n",
    "            self.calculate_indrating(ids,mydate)\n",
    "            text = \"Individual rating: \" + str(self.predictive_data) + \", and rating used for rater reputation: \" + str(self.pred_values)\n",
    "            logging.debug(text)                 \n",
    "        return(0)\n",
    "\n",
    "    ### When we want to save ratings to our system. So, we can add them, the same way as in Java.        \n",
    "    ### Except that we can add many of them at once.\n",
    "    def put_ratings(self,ratings):\n",
    "        i = 0\n",
    "        while i<len(ratings):\n",
    "            # For each of the ratings that we want to add, we transform from and to to string, just in case.\n",
    "            # \n",
    "            ratings[i]['from'] = str(ratings[i]['from'])\n",
    "            ratings[i]['to'] = str(ratings[i]['to'])\n",
    "             \n",
    "            i+=1\n",
    "        ### if we have no ratings yet in our system, we add all ratings from ground up.\n",
    "        if self.ratings == {}:\n",
    "            self.ratings = ratings\n",
    "        else:\n",
    "            self.ratings.append(ratings)\n",
    "        text = \"Adding ratings: \" + str(ratings)\n",
    "        logging.debug(text)  \n",
    "        return(0)  \n",
    "    ### This is how we get current ranks. times are basically expecting dates\n",
    "    ### when those ranks were calculated.\n",
    "    def get_ranks(self,times):\n",
    "        ### If we don't have reputations yet, we return empty array. We start with empty dictionary if there are no reputations.\n",
    "        if self.all_reputations == {}:\n",
    "            result = {}\n",
    "        else:\n",
    "            ### If there were previous reputations, we look if date we are looking for has reputations. If so, we save them\n",
    "            ### in result object.\n",
    "            if times['date'] in list(self.all_reputations.keys()):\n",
    "                result = dict(self.all_reputations[times['date']])\n",
    "            else:\n",
    "                ### If there are no reputations for that date, we work with empty dictionary.\n",
    "                result = {}\n",
    "        all_results = []\n",
    "        ### In the end we only round up the ranks when we return them.\n",
    "        for k in result.keys():\n",
    "            all_results.append({'id':k,'rank':my_round(result[k]*100,0)})  \n",
    "        #logging.debug(\"network get ranks: \",str(all_results))\n",
    "        logging.info(\"network get ranks: {0}\".format(all_results))\n",
    "        ### Now, if we have spending, we only return those that are sellers;\n",
    "        #if self.spendings>0:\n",
    "        #    my_results = dict()\n",
    "        #    for k in all_results.keys():\n",
    "        #        if k in self.sellers:\n",
    "        #            my_results[k] = all_results[k]       \n",
    "        #    all_results=my_results                    \n",
    "        return(0,all_results)\n",
    "    ### get_ranks_dict is similar as get_ranks\n",
    "    def get_ranks_dict(self,times):\n",
    "        if self.all_reputations == {}:\n",
    "            result = {}\n",
    "        else:\n",
    "            if times['date'] in list(self.all_reputations.keys()):\n",
    "                result = dict(self.all_reputations[times['date']])\n",
    "            else:\n",
    "                result = {}\n",
    "        for k in result.keys():\n",
    "            result[k] = my_round(result[k]*100,0)    \n",
    "            ### Everything is similar to get_ranks, but we only return result, not really 0 beside result.\n",
    "        #logging.debug(\"network get ranks: \" , str(result))\n",
    "        logging.info(\"network get ranks: {0}\".format(result))\n",
    "        #if self.spendings>0:\n",
    "        #    my_results = dict()\n",
    "        #    for k in result.keys():\n",
    "        #        if k in self.sellers:\n",
    "        #            my_results[k] = result[k]\n",
    "        #    result=my_results\n",
    "        return(result)    \n",
    "\n",
    "    ### Getting ratings from Python rs.\n",
    "    def get_ratings(self,times={}):\n",
    "        ### we need dates as input. In case no dates are given, we return 0.\n",
    "        if times=={}:\n",
    "            return(0,self.ratings)\n",
    "        else:\n",
    "            ### If we have dates, then we first make sure that ids are strings.\n",
    "            all_ids = str(times['ids'])\n",
    "            since = times['since']\n",
    "            until = times['until']\n",
    "            results = []\n",
    "            i = 0\n",
    "            while i<len(self.ratings):\n",
    "                ### We loop over all ratings. In some cases, ratings are lists, in this case we \"unlist\" them.\n",
    "                if type(self.ratings[i]) is list:\n",
    "                    self.ratings[i] = self.ratings[i][0]\n",
    "                ### We also look at from ids and then just make sure they are in the right time frame. If so, we add them to results.\n",
    "                if str(self.ratings[i]['from']) in all_ids:\n",
    "                    if (self.ratings[i]['time'] >= since and self.ratings[i]['time'] <= until):\n",
    "                        results.append(self.ratings[i])\n",
    "                ### Similar with \"to\" id.        \n",
    "                if self.ratings[i]['to'] in all_ids:\n",
    "                    if (self.ratings[i]['time'] >= since and self.ratings[i]['time'] <= until):\n",
    "                        results.append(self.ratings[i])                \n",
    "                i+=1\n",
    "            logging.debug(\"network get ratings on date: \" + str(times))\n",
    "            return(0,results)\n",
    "    ### put_ranks defined in similar way as in Java.\n",
    "    def put_ranks(self,dt1,mydict):\n",
    "        i = 0\n",
    "        ### dt1 is date, mydict is the dictionary with ranks.\n",
    "        while i<len(mydict):\n",
    "            ### For each rank, we convert ID to string and then convert the ranks to 0-1 range.\n",
    "            mydict[i]['id'] = str(mydict[i]['id'])\n",
    "            mydict[i]['rank'] = mydict[i]['rank']*0.01\n",
    "            i+=1   \n",
    "        ### we take myreps out of all reputations currently saved in chosen date.\n",
    "        if dt1 in self.all_reputations:\n",
    "            myreps = self.all_reputations[dt1]\n",
    "        else:\n",
    "            myreps = {}\n",
    "        ### Then we save mydict in another object, dict_values.\n",
    "        dict_values = mydict\n",
    "        i = 0\n",
    "        while i<len(dict_values):\n",
    "            ### then we save id and rank.\n",
    "            the_id = dict_values[i]['id']\n",
    "            rank = dict_values[i]['rank']\n",
    "            ### and we change the rank of the id in myreps with \n",
    "            myreps[the_id] = rank\n",
    "            i+=1\n",
    "        ### Then we change all reputations variable to all the changes we did.\n",
    "        self.all_reputations[dt1] = myreps\n",
    "        ### Also, if it is the latest date, we should take into account of it as the latest reputation.\n",
    "        if dt1 == max(self.all_reputations.keys()):\n",
    "            self.reputation = myreps\n",
    "        \n",
    "        return(0)\n",
    "\n",
    "    def get_historical_ranks(self,theid):\n",
    "        all_dates = self.all_reputations.keys()\n",
    "        ranks = []\n",
    "        for k in sorted(all_dates):\n",
    "            if theid in self.all_reputations[k].keys():\n",
    "                ranks.append(self.all_reputations[k][theid])\n",
    "        return(ranks)\n",
    "    \n",
    "    def calculate_indrating(self,ids,mydate):   \n",
    "        correlats = dict()\n",
    "        for k1 in self.predictive_data.keys():\n",
    "            k = self.predictive_data[k1]\n",
    "            thevalues = []\n",
    "            relevant_ranks = []\n",
    "            for j in k.keys():\n",
    "                nr_appearances = 1\n",
    "                \n",
    "                relevant_ranks.append(self.non_rounded_rep[j])\n",
    "                thevalues.append(k[j])\n",
    "\n",
    "                    \n",
    "            if len(relevant_ranks)!=0:        \n",
    "                cors = calculate_distance(relevant_ranks,thevalues)\n",
    "            else:\n",
    "                cors = 0\n",
    "                \n",
    "            correlats[k1] = cors \n",
    "            ### I think all cors values should be first normalized.\n",
    "        for k1 in self.predictive_data.keys():    \n",
    "            correlats[k1] = 1 - correlats[k1]\n",
    "        if len(correlats)==0:\n",
    "            max_correlats = 1\n",
    "        else:\n",
    "            max_correlats = max(correlats.values())\n",
    "        #for k1 in correlats.keys():\n",
    "        #    correlats[k1] = correlats[k1]/max_correlats \n",
    "        for k1 in self.predictive_data.keys():     \n",
    "\n",
    "            \n",
    "            if k1 in self.pred_values.keys():\n",
    "                self.pred_values[k1] = correlats[k1]\n",
    "            else:\n",
    "                self.pred_values[k1] = dict()\n",
    "                self.pred_values[k1] = correlats[k1]\n",
    "        \n",
    "        return(0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        ### we can also initialie everything.\n",
    "        self.ratings = {}\n",
    "        self.reputation = {}\n",
    "        self.all_reputations = {}\n",
    "        self.set_parameters(dict())### we need changes parameter and in our case that is an empty dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Agent: {'range': [1, 500], 'values': [100, 1000], 'transactions': 1, 'suppliers': 0.1, 'consumers': 0.9}\n",
      "Bad Agent : {'range': [501, 550], 'values': [100, 1000], 'transactions': 2, 'suppliers': 0.1, 'consumers': 0.9}\n",
      "Scam period: 10\n",
      "No RS: Good: 7679843 Bad: 744314 Good to Bad: 645420 Good/Bad: 10.318014977549797 Bad/Good_to_Bad: 1.1532242570729139 LTS: 0.0840407805211643 PFS: 0.8671340321423485\n",
      "Regular RS: Good: 7654005 Bad: 735863 Good to Bad: 344908 Good/Bad: 10.401399445277178 Bad/Good_to_Bad: 2.13350516659515 LTS: 0.0450624215688388 PFS: 0.4687122467089662\n",
      "Weighted RS: Good: 7661195 Bad: 756323 Good to Bad: 335741 Good/Bad: 10.129527992669798 Bad/Good_to_Bad: 2.252697764050265 LTS: 0.04382358104708208 PFS: 0.4439121909554516\n",
      "TOM-based RS: Good: 7666241 Bad: 731809 Good to Bad: 161576 Good/Bad: 10.475740254629281 Bad/Good_to_Bad: 4.529193692132495 LTS: 0.02107630062764789 PFS: 0.22078985090371941\n",
      "SOM-based RS: Good: 7656547 Bad: 732044 Good to Bad: 187405 Good/Bad: 10.459134970029124 Bad/Good_to_Bad: 3.9062138149996 LTS: 0.02447643826910486 PFS: 0.25600237144215376\n",
      "Scam period: 6\n",
      "No RS: Good: 7690101 Bad: 737523 Good to Bad: 667163 Good/Bad: 10.426930414373517 Bad/Good_to_Bad: 1.1054614839252177 LTS: 0.08675607771601439 PFS: 0.9045995853688631\n",
      "Regular RS: Good: 7649038 Bad: 735782 Good to Bad: 287595 Good/Bad: 10.395793862856118 Bad/Good_to_Bad: 2.5583963559867176 LTS: 0.03759884576334959 PFS: 0.3908698500371034\n",
      "Weighted RS: Good: 7671277 Bad: 748207 Good to Bad: 271763 Good/Bad: 10.252880553108966 Bad/Good_to_Bad: 2.7531599224324137 LTS: 0.035426044451269324 PFS: 0.3632190022279931\n",
      "TOM-based RS: Good: 7660327 Bad: 732388 Good to Bad: 49664 Good/Bad: 10.45938355079548 Bad/Good_to_Bad: 14.746858891752577 LTS: 0.00648327414743522 PFS: 0.06781105097298154\n",
      "SOM-based RS: Good: 7667049 Bad: 751545 Good to Bad: 70216 Good/Bad: 10.201716464083987 Bad/Good_to_Bad: 10.703329725418708 LTS: 0.009158151982594608 PFS: 0.09342886986141881\n",
      "Scam period: 4\n",
      "No RS: Good: 7678724 Bad: 744989 Good to Bad: 677117 Good/Bad: 10.307164266854947 Bad/Good_to_Bad: 1.1002367389978394 LTS: 0.08818092693525643 PFS: 0.9088952991252219\n",
      "Regular RS: Good: 7676668 Bad: 738118 Good to Bad: 193168 Good/Bad: 10.400326235100621 Bad/Good_to_Bad: 3.82111944007289 LTS: 0.02516300040590527 PFS: 0.26170341327538416\n",
      "Weighted RS: Good: 7690061 Bad: 749763 Good to Bad: 200929 Good/Bad: 10.256655769889951 Bad/Good_to_Bad: 3.731482264879634 LTS: 0.02612840132217417 PFS: 0.2679900181790779\n",
      "TOM-based RS: Good: 7655958 Bad: 736521 Good to Bad: 49664 Good/Bad: 10.394758601587736 Bad/Good_to_Bad: 14.830078125 LTS: 0.006486973935854925 PFS: 0.06743052811800343\n",
      "SOM-based RS: Good: 7665721 Bad: 752287 Good to Bad: 70216 Good/Bad: 10.189888965248635 Bad/Good_to_Bad: 10.713897117466104 LTS: 0.00915973852948731 PFS: 0.09333671856618551\n",
      "Scam period: 2\n",
      "No RS: Good: 7675347 Bad: 761107 Good to Bad: 684741 Good/Bad: 10.084451989010743 Bad/Good_to_Bad: 1.1115253796691011 LTS: 0.08921303492858368 PFS: 0.8996645675312407\n",
      "Regular RS: Good: 7673064 Bad: 732766 Good to Bad: 23134 Good/Bad: 10.471370123613815 Bad/Good_to_Bad: 31.674850868851042 LTS: 0.00301496247131524 PFS: 0.031570787945947275\n",
      "Weighted RS: Good: 7668835 Bad: 735766 Good to Bad: 23134 Good/Bad: 10.422926582636327 Bad/Good_to_Bad: 31.804530128814733 LTS: 0.0030166250806022035 PFS: 0.03144206174245616\n",
      "TOM-based RS: Good: 7659583 Bad: 732328 Good to Bad: 49664 Good/Bad: 10.459224555117379 Bad/Good_to_Bad: 14.745650773195877 LTS: 0.006483903888762613 PFS: 0.06781660676636699\n",
      "SOM-based RS: Good: 7670892 Bad: 743467 Good to Bad: 69827 Good/Bad: 10.317730309482466 Bad/Good_to_Bad: 10.647271112893293 LTS: 0.009102852706047744 PFS: 0.0939207792679433\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "# Reputation Scenario Test Data Generation\n",
    "def dict_sorted(d):\n",
    "\tfirst = True\n",
    "\ts = \"{\"\n",
    "\tfor key, value in sorted(d.items(), key=lambda x: x[0]): \n",
    "\t\ttemplate = \"'{}': {}\" if first else \", '{}': {}\"\n",
    "\t\ts += template.format(key, value)\n",
    "\t\tfirst = False\n",
    "\ts += \"}\"\n",
    "\treturn s\n",
    "\n",
    "\n",
    "#TODO use any other Reputation Service here\n",
    "rs = None\n",
    "#rs = AigentsAPIReputationService('http://localtest.com:1288/', 'john@doe.org', 'q', 'a', False, 'test', True)\n",
    "rs = PythonReputationService()\n",
    "if rs is not None:\n",
    "    rs.set_parameters({'fullnorm':True,'weighting':True,'logratings':False,'logranks':True})\n",
    "\n",
    "verbose = False\n",
    "\n",
    "\n",
    "days = 31\n",
    "consumers = 0.9\n",
    "suppliers = 0.1\n",
    "good_range = [1,500]\n",
    "bad_range = [501,550]\n",
    "\n",
    "good_transactions = 1\n",
    "bad_transactions = 2\n",
    "\n",
    "\n",
    "# Comparing different reputation systems (RS) for different scam periods (SP)\n",
    "good_agent = {\"range\": good_range, \"values\": [100,1000], \"transactions\": good_transactions, \"suppliers\": suppliers, \"consumers\": consumers}\n",
    "bad_agent = {\"range\": bad_range, \"values\": [100,1000], \"transactions\": bad_transactions, \"suppliers\": suppliers, \"consumers\": consumers}\n",
    "print('Good Agent:',str(good_agent))\n",
    "print('Bad Agent :',str(bad_agent))\n",
    "for sp in [10,6,4,2]:\n",
    "\n",
    "\tprint('Scam period:',str(sp))\n",
    "\tsip = sp/2\n",
    "\n",
    "\tprint('No RS:', end =\" \")\n",
    "\treputation_simulate(good_agent,bad_agent, datetime.date(2018, 1, 1), days, True, None, campaign = [sp,sip], verbose=verbose)\n",
    "\n",
    "\tprint('Regular RS:', end =\" \")\n",
    "\trs.set_parameters({'fullnorm':True,'weighting':False,'logratings':False,'denomination':False,'unrated':False,'default':0.5,'decayed':0.5,'ratings':1.0,'spendings':0.0})\n",
    "\treputation_simulate(good_agent,bad_agent, datetime.date(2018, 1, 1), days, True, rs, campaign = [sp,sip], verbose=verbose)\n",
    "\t\n",
    "\tprint('Weighted RS:', end =\" \")\n",
    "\trs.set_parameters({'fullnorm':True,'weighting':True ,'logratings':False,'denomination':True ,'unrated':False,'default':0.5,'decayed':0.5,'ratings':1.0,'spendings':0.0})\n",
    "\treputation_simulate(good_agent,bad_agent, datetime.date(2018, 1, 1), days, True, rs, campaign = [sp,sip], verbose=verbose)\n",
    "\n",
    "\tprint('TOM-based RS:', end =\" \")\n",
    "\trs.set_parameters({'fullnorm':True,'weighting':True ,'logratings':False,'denomination':True ,'unrated':True ,'default':0.0,'decayed':0.5,'ratings':1.0,'spendings':0.0})\n",
    "\treputation_simulate(good_agent,bad_agent, datetime.date(2018, 1, 1), days, True, rs, campaign = [sp,sip], verbose=verbose)\n",
    "\t\n",
    "\tprint('SOM-based RS:', end =\" \")\n",
    "\trs.set_parameters({'fullnorm':True,'weighting':True ,'logratings':False,'denomination':True ,'unrated':False,'default':0.0,'decayed':0.5,'ratings':0.5,'spendings':0.5})\n",
    "\treputation_simulate(good_agent,bad_agent, datetime.date(2018, 1, 1), days, True, rs, campaign = [sp,sip], verbose=verbose)\n",
    "\n",
    "del rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Agent: {'range': [1, 250], 'values': [100, 1000], 'transactions': 1, 'suppliers': 0.1, 'consumers': 0.9}\n",
      "Bad Agent : {'range': [250, 300], 'values': [100, 1000], 'transactions': 2, 'suppliers': 0.1, 'consumers': 0.9}\n",
      "Scam period: 10\n",
      "No RS: Good: 1869811 Bad: 254171 Good to Bad: 286151 Good/Bad: 7.356508020191131 Bad/Good_to_Bad: 0.8882408239006678 LTS: 0.15303739254930043 PFS: 1.1258208056780672\n",
      "Regular RS: Good: 1856184 Bad: 259365 Good to Bad: 127830 Good/Bad: 7.1566479671505405 Bad/Good_to_Bad: 2.028983806618165 LTS: 0.06886709507247127 PFS: 0.49285755595396447\n",
      "Weighted RS: Good: 1865726 Bad: 257625 Good to Bad: 129421 Good/Bad: 7.242022319262494 Bad/Good_to_Bad: 1.9905965801531436 LTS: 0.06936763490458941 PFS: 0.5023619602134886\n",
      "TOM-based RS: Good: 1849405 Bad: 255351 Good to Bad: 96766 Good/Bad: 7.242599402391218 Bad/Good_to_Bad: 2.6388504226691194 LTS: 0.05232277408139375 PFS: 0.37895289229335305\n",
      "SOM-based RS: Good: 1865926 Bad: 254165 Good to Bad: 210875 Good/Bad: 7.341396337025161 Bad/Good_to_Bad: 1.2052874925903971 LTS: 0.1130135921788967 PFS: 0.8296775716562076\n",
      "Scam period: 6\n",
      "No RS: Good: 1861064 Bad: 309969 Good to Bad: 305241 Good/Bad: 6.004032661330649 Bad/Good_to_Bad: 1.015489400178875 LTS: 0.16401424131572048 PFS: 0.9847468617829525\n",
      "Regular RS: Good: 1869311 Bad: 298831 Good to Bad: 124664 Good/Bad: 6.2554119217885695 Bad/Good_to_Bad: 2.3970913816338317 LTS: 0.06668981244961379 PFS: 0.41717224785915785\n",
      "Weighted RS: Good: 1870816 Bad: 298279 Good to Bad: 127924 Good/Bad: 6.2720339011462425 Bad/Good_to_Bad: 2.3316891279197023 LTS: 0.06837871816362485 PFS: 0.4288736384391794\n",
      "TOM-based RS: Good: 1859106 Bad: 307069 Good to Bad: 44759 Good/Bad: 6.054359117983255 Bad/Good_to_Bad: 6.8604973301458925 LTS: 0.024075550291376608 PFS: 0.14576202742706038\n",
      "SOM-based RS: Good: 1848373 Bad: 305774 Good to Bad: 161347 Good/Bad: 6.044899173899678 Bad/Good_to_Bad: 1.8951328503163989 LTS: 0.08729136381022662 PFS: 0.527667492985015\n",
      "Scam period: 4\n",
      "No RS: Good: 1864143 Bad: 360545 Good to Bad: 315390 Good/Bad: 5.170347668113551 Bad/Good_to_Bad: 1.143171945844827 LTS: 0.16918766425107945 PFS: 0.874759045334147\n",
      "Regular RS: Good: 1859392 Bad: 352946 Good to Bad: 106539 Good/Bad: 5.268205334527095 Bad/Good_to_Bad: 3.3128337979519236 LTS: 0.057297761849034526 PFS: 0.30185637462954673\n",
      "Weighted RS: Good: 1864514 Bad: 358765 Good to Bad: 95486 Good/Bad: 5.197034270344097 Bad/Good_to_Bad: 3.7572523720754876 LTS: 0.051212273010553956 PFS: 0.26615193789806696\n",
      "TOM-based RS: Good: 1847063 Bad: 359647 Good to Bad: 44759 Good/Bad: 5.135766459889837 Bad/Good_to_Bad: 8.035188453718805 LTS: 0.024232524824545777 PFS: 0.12445258823235006\n",
      "SOM-based RS: Good: 1866617 Bad: 344179 Good to Bad: 161347 Good/Bad: 5.423390154541678 Bad/Good_to_Bad: 2.1331602075030833 LTS: 0.08643819273048516 PFS: 0.46878804343088915\n",
      "Scam period: 2\n",
      "No RS: Good: 1855576 Bad: 364911 Good to Bad: 318976 Good/Bad: 5.085009769505441 Bad/Good_to_Bad: 1.1440076996388444 LTS: 0.1719013395301513 PFS: 0.8741199909018912\n",
      "Regular RS: Good: 1852735 Bad: 345944 Good to Bad: 20272 Good/Bad: 5.355592234581319 Bad/Good_to_Bad: 17.06511444356748 LTS: 0.01094166192142967 PFS: 0.05859907961982286\n",
      "Weighted RS: Good: 1849666 Bad: 344139 Good to Bad: 20272 Good/Bad: 5.374764266764301 Bad/Good_to_Bad: 16.97607537490134 LTS: 0.010959816529038215 PFS: 0.05890643025056736\n",
      "TOM-based RS: Good: 1846927 Bad: 361321 Good to Bad: 44759 Good/Bad: 5.1115960600131185 Bad/Good_to_Bad: 8.072588753099936 LTS: 0.02423430920659019 PFS: 0.12387599945754606\n",
      "SOM-based RS: Good: 1869449 Bad: 356155 Good to Bad: 161723 Good/Bad: 5.24897586724881 Bad/Good_to_Bad: 2.202253235470527 LTS: 0.08650837760217048 PFS: 0.45408038634864034\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "# Reputation Scenario Test Data Generation\n",
    "def dict_sorted(d):\n",
    "\tfirst = True\n",
    "\ts = \"{\"\n",
    "\tfor key, value in sorted(d.items(), key=lambda x: x[0]): \n",
    "\t\ttemplate = \"'{}': {}\" if first else \", '{}': {}\"\n",
    "\t\ts += template.format(key, value)\n",
    "\t\tfirst = False\n",
    "\ts += \"}\"\n",
    "\treturn s\n",
    "\n",
    "\n",
    "#TODO use any other Reputation Service here\n",
    "rs = None\n",
    "#rs = AigentsAPIReputationService('http://localtest.com:1288/', 'john@doe.org', 'q', 'a', False, 'test', True)\n",
    "rs = PythonReputationService()\n",
    "if rs is not None:\n",
    "    rs.set_parameters({'fullnorm':True,'weighting':True,'logratings':False,'logranks':True})\n",
    "\n",
    "verbose = False\n",
    "\n",
    "\n",
    "days = 15\n",
    "consumers = 0.9\n",
    "suppliers = 0.1\n",
    "good_range = [1,250]\n",
    "bad_range = [250,300]\n",
    "\n",
    "good_transactions = 1\n",
    "bad_transactions = 2\n",
    "\n",
    "\n",
    "# Comparing different reputation systems (RS) for different scam periods (SP)\n",
    "good_agent = {\"range\": good_range, \"values\": [100,1000], \"transactions\": good_transactions, \"suppliers\": suppliers, \"consumers\": consumers}\n",
    "bad_agent = {\"range\": bad_range, \"values\": [100,1000], \"transactions\": bad_transactions, \"suppliers\": suppliers, \"consumers\": consumers}\n",
    "print('Good Agent:',str(good_agent))\n",
    "print('Bad Agent :',str(bad_agent))\n",
    "for sp in [10,6,4,2]:\n",
    "\n",
    "\tprint('Scam period:',str(sp))\n",
    "\tsip = sp/2\n",
    "\n",
    "\tprint('No RS:', end =\" \")\n",
    "\treputation_simulate(good_agent,bad_agent, datetime.date(2018, 1, 1), days, True, None, campaign = [sp,sip], verbose=verbose)\n",
    "\n",
    "\tprint('Regular RS:', end =\" \")\n",
    "\trs.set_parameters({'fullnorm':True,'weighting':False,'logratings':False,'denomination':False,'unrated':False,'default':0.5,'decayed':0.5,'ratings':1.0,'spendings':0.0})\n",
    "\treputation_simulate(good_agent,bad_agent, datetime.date(2018, 1, 1), days, True, rs, campaign = [sp,sip], verbose=verbose)\n",
    "\t\n",
    "\tprint('Weighted RS:', end =\" \")\n",
    "\trs.set_parameters({'fullnorm':True,'weighting':True ,'logratings':False,'denomination':True ,'unrated':False,'default':0.5,'decayed':0.5,'ratings':1.0,'spendings':0.0})\n",
    "\treputation_simulate(good_agent,bad_agent, datetime.date(2018, 1, 1), days, True, rs, campaign = [sp,sip], verbose=verbose)\n",
    "\n",
    "\tprint('TOM-based RS:', end =\" \")\n",
    "\trs.set_parameters({'fullnorm':True,'weighting':True ,'logratings':False,'denomination':True ,'unrated':True ,'default':0.0,'decayed':0.5,'ratings':1.0,'spendings':0.0})\n",
    "\treputation_simulate(good_agent,bad_agent, datetime.date(2018, 1, 1), days, True, rs, campaign = [sp,sip], verbose=verbose)\n",
    "\t\n",
    "\tprint('SOM-based RS:', end =\" \")\n",
    "\trs.set_parameters({'fullnorm':True,'weighting':True ,'logratings':False,'denomination':True ,'unrated':False,'default':0.0,'decayed':0.5,'ratings':0.5,'spendings':0.5})\n",
    "\treputation_simulate(good_agent,bad_agent, datetime.date(2018, 1, 1), days, True, rs, campaign = [sp,sip], verbose=verbose)\n",
    "\n",
    "del rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Agent: {'range': [1, 500], 'values': [100, 1000], 'transactions': 1, 'suppliers': 0.1, 'consumers': 0.9}\n",
      "Bad Agent : {'range': [501, 550], 'values': [100, 1000], 'transactions': 2, 'suppliers': 0.1, 'consumers': 0.9}\n",
      "Scam period: 20\n",
      "No RS: Good: 7684382 Bad: 538529 Good to Bad: 611270 Good/Bad: 14.269207415013861 Bad/Good_to_Bad: 0.881000212671978 LTS: 0.07954706051833446 PFS: 1.1350735057907746\n",
      "Regular RS: Good: 7653715 Bad: 546332 Good to Bad: 277074 Good/Bad: 14.009274580291837 Bad/Good_to_Bad: 1.9717909294989786 LTS: 0.03620124344844301 PFS: 0.5071531596172291\n",
      "Weighted RS: Good: 7649774 Bad: 545798 Good to Bad: 278984 Good/Bad: 14.0157604095288 Bad/Good_to_Bad: 1.956377426662461 LTS: 0.03646957413382408 PFS: 0.5111488132972272\n",
      "TOM-based RS: Good: 7661687 Bad: 549034 Good to Bad: 255151 Good/Bad: 13.954849790723344 Bad/Good_to_Bad: 2.151800306485179 LTS: 0.033302195717470576 PFS: 0.4647271389385721\n",
      "SOM-based RS: Good: 7651157 Bad: 546474 Good to Bad: 292504 Good/Bad: 14.000953384790494 Bad/Good_to_Bad: 1.8682616306101796 LTS: 0.038230035013005224 PFS: 0.5352569381159945\n",
      "Scam period: 15\n",
      "No RS: Good: 7690505 Bad: 702483 Good to Bad: 619108 Good/Bad: 10.947603002492587 Bad/Good_to_Bad: 1.1346695568463014 LTS: 0.08050290585598735 PFS: 0.8813138538583852\n",
      "Regular RS: Good: 7660585 Bad: 697132 Good to Bad: 327090 Good/Bad: 10.988715193105467 Bad/Good_to_Bad: 2.1313155400654256 LTS: 0.042697783524365304 PFS: 0.4691937825261213\n",
      "Weighted RS: Good: 7657226 Bad: 706617 Good to Bad: 309224 Good/Bad: 10.836458788848839 Bad/Good_to_Bad: 2.285129873489768 LTS: 0.040383292853051485 PFS: 0.43761188876010626\n",
      "TOM-based RS: Good: 7647212 Bad: 701921 Good to Bad: 245136 Good/Bad: 10.894690428125102 Bad/Good_to_Bad: 2.86339419750669 LTS: 0.032055604055438766 PFS: 0.34923588267055694\n",
      "SOM-based RS: Good: 7664113 Bad: 694069 Good to Bad: 254948 Good/Bad: 11.042292625084826 Bad/Good_to_Bad: 2.7223943706167533 LTS: 0.033265167149805853 PFS: 0.3673237098905152\n",
      "Scam period: 12\n",
      "No RS: Good: 7686931 Bad: 653402 Good to Bad: 638025 Good/Bad: 11.764474244033535 Bad/Good_to_Bad: 1.0241009364836802 LTS: 0.08300126539447278 PFS: 0.976466248955467\n",
      "Regular RS: Good: 7645574 Bad: 660487 Good to Bad: 275690 Good/Bad: 11.575661595156301 Bad/Good_to_Bad: 2.3957597301316698 LTS: 0.03605877073454524 PFS: 0.41740412756042133\n",
      "Weighted RS: Good: 7659005 Bad: 635183 Good to Bad: 284176 Good/Bad: 12.057950228516821 Bad/Good_to_Bad: 2.2351746804797026 LTS: 0.03710351409876348 PFS: 0.4473923263059622\n",
      "TOM-based RS: Good: 7670185 Bad: 626517 Good to Bad: 210843 Good/Bad: 12.242580807863154 Bad/Good_to_Bad: 2.971485892346438 LTS: 0.027488645971381395 PFS: 0.33653196960337867\n",
      "SOM-based RS: Good: 7666350 Bad: 665792 Good to Bad: 193816 Good/Bad: 11.514632197443046 Bad/Good_to_Bad: 3.4351756304949026 LTS: 0.025281392057498027 PFS: 0.29110593098144766\n",
      "Scam period: 8\n",
      "No RS: Good: 7689365 Bad: 742057 Good to Bad: 652576 Good/Bad: 10.362229586136914 Bad/Good_to_Bad: 1.1371196611582406 LTS: 0.08486734600321352 PFS: 0.8794149236514176\n",
      "Regular RS: Good: 7663388 Bad: 756347 Good to Bad: 268549 Good/Bad: 10.13210603069755 Bad/Good_to_Bad: 2.816420839399886 LTS: 0.03504311669981997 PFS: 0.355060574048684\n",
      "Weighted RS: Good: 7663045 Bad: 760368 Good to Bad: 270694 Good/Bad: 10.078074037834313 Bad/Good_to_Bad: 2.80895771609271 LTS: 0.03532460007738438 PFS: 0.35600393493676746\n",
      "TOM-based RS: Good: 7687574 Bad: 742797 Good to Bad: 139221 Good/Bad: 10.349495218747517 Bad/Good_to_Bad: 5.335380438295947 LTS: 0.018109874454541836 PFS: 0.18742805907939855\n",
      "SOM-based RS: Good: 7674859 Bad: 741572 Good to Bad: 94250 Good/Bad: 10.349445502257367 Bad/Good_to_Bad: 7.868137931034482 LTS: 0.012280355899697962 PFS: 0.1270948741322488\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "# Reputation Scenario Test Data Generation\n",
    "def dict_sorted(d):\n",
    "\tfirst = True\n",
    "\ts = \"{\"\n",
    "\tfor key, value in sorted(d.items(), key=lambda x: x[0]): \n",
    "\t\ttemplate = \"'{}': {}\" if first else \", '{}': {}\"\n",
    "\t\ts += template.format(key, value)\n",
    "\t\tfirst = False\n",
    "\ts += \"}\"\n",
    "\treturn s\n",
    "\n",
    "\n",
    "#TODO use any other Reputation Service here\n",
    "rs = None\n",
    "#rs = AigentsAPIReputationService('http://localtest.com:1288/', 'john@doe.org', 'q', 'a', False, 'test', True)\n",
    "rs = PythonReputationService()\n",
    "if rs is not None:\n",
    "    rs.set_parameters({'fullnorm':True,'weighting':True,'logratings':False,'logranks':True})\n",
    "\n",
    "verbose = False\n",
    "\n",
    "\n",
    "days = 31\n",
    "consumers = 0.9\n",
    "suppliers = 0.1\n",
    "good_range = [1,500]\n",
    "bad_range = [501,550]\n",
    "\n",
    "good_transactions = 1\n",
    "bad_transactions = 2\n",
    "\n",
    "\n",
    "# Comparing different reputation systems (RS) for different scam periods (SP)\n",
    "good_agent = {\"range\": good_range, \"values\": [100,1000], \"transactions\": good_transactions, \"suppliers\": suppliers, \"consumers\": consumers}\n",
    "bad_agent = {\"range\": bad_range, \"values\": [100,1000], \"transactions\": bad_transactions, \"suppliers\": suppliers, \"consumers\": consumers}\n",
    "print('Good Agent:',str(good_agent))\n",
    "print('Bad Agent :',str(bad_agent))\n",
    "for sp in [20,15,12,8]:\n",
    "\n",
    "\tprint('Scam period:',str(sp))\n",
    "\tsip = sp/2\n",
    "\n",
    "\tprint('No RS:', end =\" \")\n",
    "\treputation_simulate(good_agent,bad_agent, datetime.date(2018, 1, 1), days, True, None, campaign = [sp,sip], verbose=verbose)\n",
    "\n",
    "\tprint('Regular RS:', end =\" \")\n",
    "\trs.set_parameters({'fullnorm':True,'weighting':False,'logratings':False,'denomination':False,'unrated':False,'default':0.5,'decayed':0.5,'ratings':1.0,'spendings':0.0})\n",
    "\treputation_simulate(good_agent,bad_agent, datetime.date(2018, 1, 1), days, True, rs, campaign = [sp,sip], verbose=verbose)\n",
    "\t\n",
    "\tprint('Weighted RS:', end =\" \")\n",
    "\trs.set_parameters({'fullnorm':True,'weighting':True ,'logratings':False,'denomination':True ,'unrated':False,'default':0.5,'decayed':0.5,'ratings':1.0,'spendings':0.0})\n",
    "\treputation_simulate(good_agent,bad_agent, datetime.date(2018, 1, 1), days, True, rs, campaign = [sp,sip], verbose=verbose)\n",
    "\n",
    "\tprint('TOM-based RS:', end =\" \")\n",
    "\trs.set_parameters({'fullnorm':True,'weighting':True ,'logratings':False,'denomination':True ,'unrated':True ,'default':0.0,'decayed':0.5,'ratings':1.0,'spendings':0.0})\n",
    "\treputation_simulate(good_agent,bad_agent, datetime.date(2018, 1, 1), days, True, rs, campaign = [sp,sip], verbose=verbose)\n",
    "\t\n",
    "\tprint('SOM-based RS:', end =\" \")\n",
    "\trs.set_parameters({'fullnorm':True,'weighting':True ,'logratings':False,'denomination':True ,'unrated':False,'default':0.0,'decayed':0.5,'ratings':0.5,'spendings':0.5})\n",
    "\treputation_simulate(good_agent,bad_agent, datetime.date(2018, 1, 1), days, True, rs, campaign = [sp,sip], verbose=verbose)\n",
    "\n",
    "del rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Agent: {'range': [1, 750], 'values': [100, 1000], 'transactions': 1, 'suppliers': 0.1, 'consumers': 0.9}\n",
      "Bad Agent : {'range': [751, 800], 'values': [100, 1000], 'transactions': 2, 'suppliers': 0.1, 'consumers': 0.9}\n",
      "Scam period: 10\n",
      "No RS: Good: 33420499 Bad: 2205323 Good to Bad: 1942642 Good/Bad: 15.154468982548135 Bad/Good_to_Bad: 1.1352184293348955 LTS: 0.0581272589616331 PFS: 0.8808877429746119\n",
      "Regular RS: Good: 33392315 Bad: 2256211 Good to Bad: 895192 Good/Bad: 14.800173831259576 Bad/Good_to_Bad: 2.5203654634983335 LTS: 0.026808324011078598 PFS: 0.3967678554886932\n",
      "Weighted RS: Good: 33369692 Bad: 2234046 Good to Bad: 886622 Good/Bad: 14.936886706898605 Bad/Good_to_Bad: 2.519727685530023 LTS: 0.02656967885708984 PFS: 0.39686828292703014\n",
      "TOM-based RS: Good: 33401093 Bad: 2215890 Good to Bad: 410073 Good/Bad: 15.073443627616895 Bad/Good_to_Bad: 5.403647643224499 LTS: 0.012277232963603916 PFS: 0.18506017898000351\n",
      "SOM-based RS: Good: 33400472 Bad: 2217178 Good to Bad: 321122 Good/Bad: 15.064407097671003 Bad/Good_to_Bad: 6.904472443494996 LTS: 0.009614295271036888 PFS: 0.14483365792011285\n",
      "Scam period: 6\n",
      "No RS: Good: 33415826 Bad: 2189238 Good to Bad: 1996075 Good/Bad: 15.263678960441943 Bad/Good_to_Bad: 1.0967714138997784 LTS: 0.05973442045095638 PFS: 0.9117670166514559\n",
      "Regular RS: Good: 33392931 Bad: 2217295 Good to Bad: 717537 Good/Bad: 15.060211203290496 Bad/Good_to_Bad: 3.0901472676670334 LTS: 0.021487691511715458 PFS: 0.32360917243758724\n",
      "Weighted RS: Good: 33421366 Bad: 2220836 Good to Bad: 727530 Good/Bad: 15.049002267614538 Bad/Good_to_Bad: 3.0525696534850795 LTS: 0.021768410064388153 PFS: 0.32759285242134045\n",
      "TOM-based RS: Good: 33395427 Bad: 2221898 Good to Bad: 53730 Good/Bad: 15.030135046703315 Bad/Good_to_Bad: 41.353024381165085 LTS: 0.0016089029195524285 PFS: 0.02418202815790824\n",
      "SOM-based RS: Good: 33410910 Bad: 2217005 Good to Bad: 70846 Good/Bad: 15.070290775167399 Bad/Good_to_Bad: 31.293298139626796 LTS: 0.002120445088146357 PFS: 0.03195572405114107\n",
      "Scam period: 4\n",
      "No RS: Good: 33396884 Bad: 2183506 Good to Bad: 2012314 Good/Bad: 15.295073152993396 Bad/Good_to_Bad: 1.0850722104005637 LTS: 0.06025454350771168 PFS: 0.9215976507506735\n",
      "Regular RS: Good: 33386918 Bad: 2175873 Good to Bad: 535200 Good/Bad: 15.344148302773185 Bad/Good_to_Bad: 4.065532511210763 LTS: 0.016030230762839506 PFS: 0.2459702381526863\n",
      "Weighted RS: Good: 33360340 Bad: 2159096 Good to Bad: 565620 Good/Bad: 15.45106841011238 Bad/Good_to_Bad: 3.8172200417241258 LTS: 0.01695486316985978 PFS: 0.2619707507215983\n",
      "TOM-based RS: Good: 33366441 Bad: 2173798 Good to Bad: 53730 Good/Bad: 15.349375148932882 Bad/Good_to_Bad: 40.45780755630002 LTS: 0.0016103006011339357 PFS: 0.024717108029356914\n",
      "SOM-based RS: Good: 33384449 Bad: 2167682 Good to Bad: 70846 Good/Bad: 15.400990089874806 Bad/Good_to_Bad: 30.597097930722978 LTS: 0.0021221257837743556 PFS: 0.032682838165376656\n",
      "Scam period: 2\n",
      "No RS: Good: 33411305 Bad: 2236176 Good to Bad: 2028707 Good/Bad: 14.941268039724958 Bad/Good_to_Bad: 1.1022666161254435 LTS: 0.06071917873306655 PFS: 0.9072215246027147\n",
      "Regular RS: Good: 33362737 Bad: 2231306 Good to Bad: 24646 Good/Bad: 14.952111902177469 Bad/Good_to_Bad: 90.53420433336038 LTS: 0.0007387283603260728 PFS: 0.011045549108907518\n",
      "Weighted RS: Good: 33356457 Bad: 2247151 Good to Bad: 24646 Good/Bad: 14.843887660419794 Bad/Good_to_Bad: 91.17710784711515 LTS: 0.0007388674402680116 PFS: 0.010967665279280298\n",
      "TOM-based RS: Good: 33383937 Bad: 2236277 Good to Bad: 53730 Good/Bad: 14.928355029363535 Bad/Good_to_Bad: 41.62064023822818 LTS: 0.00160945666773814 PFS: 0.02402654054037134\n",
      "SOM-based RS: Good: 33390073 Bad: 2254948 Good to Bad: 69467 Good/Bad: 14.807469174455465 Bad/Good_to_Bad: 32.460707962053924 LTS: 0.0020804686470736375 PFS: 0.030806475359963954\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "# Reputation Scenario Test Data Generation\n",
    "def dict_sorted(d):\n",
    "\tfirst = True\n",
    "\ts = \"{\"\n",
    "\tfor key, value in sorted(d.items(), key=lambda x: x[0]): \n",
    "\t\ttemplate = \"'{}': {}\" if first else \", '{}': {}\"\n",
    "\t\ts += template.format(key, value)\n",
    "\t\tfirst = False\n",
    "\ts += \"}\"\n",
    "\treturn s\n",
    "\n",
    "\n",
    "#TODO use any other Reputation Service here\n",
    "rs = None\n",
    "#rs = AigentsAPIReputationService('http://localtest.com:1288/', 'john@doe.org', 'q', 'a', False, 'test', True)\n",
    "rs = PythonReputationService()\n",
    "if rs is not None:\n",
    "    rs.set_parameters({'fullnorm':True,'weighting':True,'logratings':False,'logranks':True})\n",
    "\n",
    "verbose = False\n",
    "\n",
    "\n",
    "days = 90\n",
    "consumers = 0.9\n",
    "suppliers = 0.1\n",
    "good_range = [1,750]\n",
    "bad_range = [751,800]\n",
    "\n",
    "good_transactions = 1\n",
    "bad_transactions = 2\n",
    "\n",
    "\n",
    "# Comparing different reputation systems (RS) for different scam periods (SP)\n",
    "good_agent = {\"range\": good_range, \"values\": [100,1000], \"transactions\": good_transactions, \"suppliers\": suppliers, \"consumers\": consumers}\n",
    "bad_agent = {\"range\": bad_range, \"values\": [100,1000], \"transactions\": bad_transactions, \"suppliers\": suppliers, \"consumers\": consumers}\n",
    "print('Good Agent:',str(good_agent))\n",
    "print('Bad Agent :',str(bad_agent))\n",
    "for sp in [10,6,4,2]:\n",
    "\n",
    "\tprint('Scam period:',str(sp))\n",
    "\tsip = sp/2\n",
    "\n",
    "\tprint('No RS:', end =\" \")\n",
    "\treputation_simulate(good_agent,bad_agent, datetime.date(2018, 1, 1), days, True, None, campaign = [sp,sip], verbose=verbose)\n",
    "\n",
    "\tprint('Regular RS:', end =\" \")\n",
    "\trs.set_parameters({'fullnorm':True,'weighting':False,'logratings':False,'denomination':False,'unrated':False,'default':0.5,'decayed':0.5,'ratings':1.0,'spendings':0.0})\n",
    "\treputation_simulate(good_agent,bad_agent, datetime.date(2018, 1, 1), days, True, rs, campaign = [sp,sip], verbose=verbose)\n",
    "\t\n",
    "\tprint('Weighted RS:', end =\" \")\n",
    "\trs.set_parameters({'fullnorm':True,'weighting':True ,'logratings':False,'denomination':True ,'unrated':False,'default':0.5,'decayed':0.5,'ratings':1.0,'spendings':0.0})\n",
    "\treputation_simulate(good_agent,bad_agent, datetime.date(2018, 1, 1), days, True, rs, campaign = [sp,sip], verbose=verbose)\n",
    "\n",
    "\tprint('TOM-based RS:', end =\" \")\n",
    "\trs.set_parameters({'fullnorm':True,'weighting':True ,'logratings':False,'denomination':True ,'unrated':True ,'default':0.0,'decayed':0.5,'ratings':1.0,'spendings':0.0})\n",
    "\treputation_simulate(good_agent,bad_agent, datetime.date(2018, 1, 1), days, True, rs, campaign = [sp,sip], verbose=verbose)\n",
    "\t\n",
    "\tprint('SOM-based RS:', end =\" \")\n",
    "\trs.set_parameters({'fullnorm':True,'weighting':True ,'logratings':False,'denomination':True ,'unrated':False,'default':0.0,'decayed':0.5,'ratings':0.5,'spendings':0.5})\n",
    "\treputation_simulate(good_agent,bad_agent, datetime.date(2018, 1, 1), days, True, rs, campaign = [sp,sip], verbose=verbose)\n",
    "\n",
    "del rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
